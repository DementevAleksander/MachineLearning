{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1W8R8WgZceEk"
   },
   "source": [
    "# Character-Level LSTM\n",
    "\n",
    "Семинар основан на [материале](https://github.com/hse-ds/iad-deep-learning/blob/master/2021/seminars/sem08/sem08_task.ipynb) с майнора по DL.\n",
    "\n",
    "На этом семинаре поговорим про рекуррентные нейронные сети (Recurrent Neural Networ, RNN). Мы обучим модель на тексте книги \"Анна Каренина\", после чего попробуем генерировать новый текст.\n",
    "\n",
    "**Модель сможет генерировать новый текст на основе текста \"Анны Карениной\"!**\n",
    "\n",
    "Можно посмотреть полезную [статью про RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) и [реализацию в Torch](https://github.com/karpathy/char-rnn).\n",
    "\n",
    "Ообщая архитектура RNN:\n",
    "\n",
    "<img src=\"https://github.com/udacity/deep-learning-v2-pytorch/blob/master/recurrent-neural-networks/char-rnn/assets/charseq.jpeg?raw=1\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sqUOE2flceEl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wHfCDyzceEl"
   },
   "source": [
    "## Загрузим данные\n",
    "\n",
    "Загрузим текстовый файл \"Анны Карениной\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b34kfqIOceEl"
   },
   "outputs": [],
   "source": [
    "# open text file and read in data as `text`\n",
    "with open('anna.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jp1Ljc4mceEl"
   },
   "source": [
    "Посмотрим первые 100 символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7VctmLQfceEl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverything was in confusion in the Oblonskys' house. The wife had\\ndiscovered that the husband was carrying on\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iC21bopceEl"
   },
   "source": [
    "### Токенизация\n",
    "\n",
    "В ячейках ниже создадим два **словаря** для преобразования символов в целые числа и обратно. Кодирование символов как целых чисел упрощает их использование в качестве входных данных в сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tYVlmnxLceEl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-', ')', 'J', 'i', '6', 'f', 'j', 'B', ',', '3', 'g', 'R', 'b', 'v', 'r', 'D', 'q', ' ', '/', 'H', 'Y', 'Z', 'x', 'V', '1', 'w', '(', 'd', 's', 'I', 'm', 'k', 'l', '*', 'X', 'p', 'y', 'W', 'z', 'a', 'P', 'M', 'O', 'U', '&', '8', '_', 'G', 'C', 'Q', '\\n', 'S', 't', 'K', 'c', '7', '`', '4', 'h', '!', '2', 'E', '.', ':', ';', '5', 'A', \"'\", '\"', 'N', 'e', '@', '9', '%', '$', 'T', 'n', 'F', '?', 'u', 'L', '0', 'o')\n"
     ]
    }
   ],
   "source": [
    "# encode the text and map each character to an integer and vice versa\n",
    "\n",
    "# we create two dictionaries:\n",
    "# 1. int2char, which maps integers to characters\n",
    "# 2. char2int, which maps characters to unique integers\n",
    "chars = tuple(set(text))\n",
    "print(chars)\n",
    "\n",
    "# set(text) собирает уникальные символы (буквы, пробелы, знаки препинания и т. д.) из текста.\n",
    "# tuple(set(text)) превращает множество в кортеж (упорядоченная структура)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '-', 1: ')', 2: 'J', 3: 'i', 4: '6', 5: 'f', 6: 'j', 7: 'B', 8: ',', 9: '3', 10: 'g', 11: 'R', 12: 'b', 13: 'v', 14: 'r', 15: 'D', 16: 'q', 17: ' ', 18: '/', 19: 'H', 20: 'Y', 21: 'Z', 22: 'x', 23: 'V', 24: '1', 25: 'w', 26: '(', 27: 'd', 28: 's', 29: 'I', 30: 'm', 31: 'k', 32: 'l', 33: '*', 34: 'X', 35: 'p', 36: 'y', 37: 'W', 38: 'z', 39: 'a', 40: 'P', 41: 'M', 42: 'O', 43: 'U', 44: '&', 45: '8', 46: '_', 47: 'G', 48: 'C', 49: 'Q', 50: '\\n', 51: 'S', 52: 't', 53: 'K', 54: 'c', 55: '7', 56: '`', 57: '4', 58: 'h', 59: '!', 60: '2', 61: 'E', 62: '.', 63: ':', 64: ';', 65: '5', 66: 'A', 67: \"'\", 68: '\"', 69: 'N', 70: 'e', 71: '@', 72: '9', 73: '%', 74: '$', 75: 'T', 76: 'n', 77: 'F', 78: '?', 79: 'u', 80: 'L', 81: '0', 82: 'o'}\n"
     ]
    }
   ],
   "source": [
    "int2char = dict(enumerate(chars))\n",
    "print(int2char)\n",
    "\n",
    "# enumerate(chars) пронумеровывает каждый символ.\n",
    "# Пример: {0: 'a', 1: 'b', 2: ' ', ...}.\n",
    "# char2int: сопоставляет символ с числом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-': 0, ')': 1, 'J': 2, 'i': 3, '6': 4, 'f': 5, 'j': 6, 'B': 7, ',': 8, '3': 9, 'g': 10, 'R': 11, 'b': 12, 'v': 13, 'r': 14, 'D': 15, 'q': 16, ' ': 17, '/': 18, 'H': 19, 'Y': 20, 'Z': 21, 'x': 22, 'V': 23, '1': 24, 'w': 25, '(': 26, 'd': 27, 's': 28, 'I': 29, 'm': 30, 'k': 31, 'l': 32, '*': 33, 'X': 34, 'p': 35, 'y': 36, 'W': 37, 'z': 38, 'a': 39, 'P': 40, 'M': 41, 'O': 42, 'U': 43, '&': 44, '8': 45, '_': 46, 'G': 47, 'C': 48, 'Q': 49, '\\n': 50, 'S': 51, 't': 52, 'K': 53, 'c': 54, '7': 55, '`': 56, '4': 57, 'h': 58, '!': 59, '2': 60, 'E': 61, '.': 62, ':': 63, ';': 64, '5': 65, 'A': 66, \"'\": 67, '\"': 68, 'N': 69, 'e': 70, '@': 71, '9': 72, '%': 73, '$': 74, 'T': 75, 'n': 76, 'F': 77, '?': 78, 'u': 79, 'L': 80, '0': 81, 'o': 82}\n"
     ]
    }
   ],
   "source": [
    "char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "print(char2int)\n",
    "\n",
    "# Обратный словарь: { 'a': 0, 'b': 1, ' ': 2, ... }."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 58, 39, ..., 28, 62, 50])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode the text\n",
    "encoded = np.array([char2int[ch] for ch in text])\n",
    "encoded\n",
    "\n",
    "# Каждый символ из текста заменяется на его числовое представление, используя словарь char2int.\n",
    "# Результат сохраняется в массиве encoded (числовая версия текста)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJIzwzSwceEl"
   },
   "source": [
    "Посмотрим как символы закодировались целыми числами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WK1MYr_9ceEl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 58, 39, 35, 52, 70, 14, 17, 24, 50, 50, 50, 19, 39, 35, 35, 36,\n",
       "       17,  5, 39, 30,  3, 32,  3, 70, 28, 17, 39, 14, 70, 17, 39, 32, 32,\n",
       "       17, 39, 32,  3, 31, 70, 64, 17, 70, 13, 70, 14, 36, 17, 79, 76, 58,\n",
       "       39, 35, 35, 36, 17,  5, 39, 30,  3, 32, 36, 17,  3, 28, 17, 79, 76,\n",
       "       58, 39, 35, 35, 36, 17,  3, 76, 17,  3, 52, 28, 17, 82, 25, 76, 50,\n",
       "       25, 39, 36, 62, 50, 50, 61, 13, 70, 14, 36, 52, 58,  3, 76])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azltQy-gceEl"
   },
   "source": [
    "## Предобработка данных\n",
    "\n",
    "Как можно видеть на изображении char-RNN выше, сеть ожидает **one-hot encoded** входа, что означает, что каждый символ преобразуется в целое число (через созданный словарь), а затем преобразуется в вектор-столбец, где только соответствующий ему целочисленный индекс будет иметь значение 1, а остальная часть вектора будет заполнена нулями. Давайте создадим для этого функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OnahALhiceEl"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "\n",
    "    # Initialize the the encoded array\n",
    "    one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
    "\n",
    "    # Fill the appropriate elements with ones\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "\n",
    "    # Finally reshape it to get back to the original array\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "L3lTdLKfceEl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# check that the function works as expected\n",
    "test_seq = np.array([[3, 5, 1]])\n",
    "one_hot = one_hot_encode(test_seq, 20)\n",
    "\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YyL91CuceEl"
   },
   "source": [
    "## Создаем mini-batch'и\n",
    "\n",
    "\n",
    "Создадим мини-батчи для обучения. На простом примере они будут выглядеть так:\n",
    "\n",
    "<img src=\"https://github.com/udacity/deep-learning-v2-pytorch/blob/master/recurrent-neural-networks/char-rnn/assets/sequence_batching@1x.png?raw=1\" width=500px>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2ECftYejnvpx"
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, batch_size, seq_length):\n",
    "    '''Create a generator that returns batches of size\n",
    "       batch_size x seq_length from arr.\n",
    "\n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       batch_size: Batch size, the number of sequences per batch\n",
    "       seq_length: Number of encoded chars in a sequence\n",
    "    '''\n",
    "\n",
    "    batch_size_total = batch_size * seq_length\n",
    "    # total number of batches we can make\n",
    "    n_batches = len(arr)//batch_size_total\n",
    "\n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches * batch_size_total]\n",
    "    # Reshape into batch_size rows\n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "\n",
    "    # iterate through the array, one sequence at a time\n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        # The features\n",
    "        x = arr[:, n:n+seq_length]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9uKOvbqceEl"
   },
   "source": [
    "### Протестируем\n",
    "\n",
    "Теперь создадим несколько наборов данных, и проверим, что происходит, когда мы создаем батчи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qtKlLXi1ceEl"
   },
   "outputs": [],
   "source": [
    "batches = get_batches(encoded, 8, 50)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Rg5MUTqqceEl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[48 58 39 35 52 70 14 17 24 50 50 50 19 39 35 35 36 17  5 39 30  3 32  3\n",
      "  70 28 17 39 14 70 17 39 32 32 17 39 32  3 31 70]\n",
      " [28 82 76 17 52 58 39 52 17 39 52 52 14 39 54 52 70 27 17 58 70 14 17 39\n",
      "  52 52 70 76 52  3 82 76 17 25 39 28 17 58 70 14]\n",
      " [70 76 27 17 82 14 17 39 17  5 82 70  8 17 58 70 17 39 13 82  3 27 70 27\n",
      "  17 58  3 28 17  5 39 52 58 70 14 62 17 19 70 50]\n",
      " [28 17 52 58 70 17 54 58  3 70  5 17 52 58 82 79 10 58 17 58  3 27 27 70\n",
      "  76 50  3 76 52 70 14 70 28 52 17 82  5 17 58  3]\n",
      " [17 28 39 25 17 58 70 14 17 52 70 39 14  0 28 52 39  3 76 70 27  8 17 35\n",
      "   3 52  3  5 79 32  8 17 28 25 70 70 52 17  5 39]\n",
      " [54 79 28 28  3 82 76 17 39 76 27 17 39 76 39 32 36 28  3 28  8 17 25 39\n",
      "  28 17  3 76 17 35 14  3 76 54  3 35 32 70 17 27]\n",
      " [17 66 76 76 39 17 58 39 27 17 28 39  3 27 17 52 58 39 52 17 15 82 32 32\n",
      "  36 17 25 82 79 32 27 17 70 22 54 79 28 70 17  3]\n",
      " [42 12 32 82 76 28 31 36 62 17 68  7 79 52 17 46 52 58 70 36 46 17 54 39\n",
      "  76 76 82 52 17 10 14 39 28 35 17 52 58 39 52  8]]\n",
      "\n",
      "y\n",
      " [[58 39 35 52 70 14 17 24 50 50 50 19 39 35 35 36 17  5 39 30  3 32  3 70\n",
      "  28 17 39 14 70 17 39 32 32 17 39 32  3 31 70 64]\n",
      " [82 76 17 52 58 39 52 17 39 52 52 14 39 54 52 70 27 17 58 70 14 17 39 52\n",
      "  52 70 76 52  3 82 76 17 25 39 28 17 58 70 14 17]\n",
      " [76 27 17 82 14 17 39 17  5 82 70  8 17 58 70 17 39 13 82  3 27 70 27 17\n",
      "  58  3 28 17  5 39 52 58 70 14 62 17 19 70 50 32]\n",
      " [17 52 58 70 17 54 58  3 70  5 17 52 58 82 79 10 58 17 58  3 27 27 70 76\n",
      "  50  3 76 52 70 14 70 28 52 17 82  5 17 58  3 28]\n",
      " [28 39 25 17 58 70 14 17 52 70 39 14  0 28 52 39  3 76 70 27  8 17 35  3\n",
      "  52  3  5 79 32  8 17 28 25 70 70 52 17  5 39 54]\n",
      " [79 28 28  3 82 76 17 39 76 27 17 39 76 39 32 36 28  3 28  8 17 25 39 28\n",
      "  17  3 76 17 35 14  3 76 54  3 35 32 70 17 27  3]\n",
      " [66 76 76 39 17 58 39 27 17 28 39  3 27 17 52 58 39 52 17 15 82 32 32 36\n",
      "  17 25 82 79 32 27 17 70 22 54 79 28 70 17  3 52]\n",
      " [12 32 82 76 28 31 36 62 17 68  7 79 52 17 46 52 58 70 36 46 17 54 39 76\n",
      "  76 82 52 17 10 14 39 28 35 17 52 58 39 52  8 50]]\n"
     ]
    }
   ],
   "source": [
    "# printing out the first 10 items in a sequence\n",
    "print('x\\n', x[:40, :40])\n",
    "print('\\ny\\n', y[:40, :40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_qHIAEIceEl"
   },
   "source": [
    "Если вы правильно реализовали get_batches, результат должен выглядеть примерно так:\n",
    "```\n",
    "x\n",
    " [[25  8 60 11 45 27 28 73  1  2]\n",
    " [17  7 20 73 45  8 60 45 73 60]\n",
    " [27 20 80 73  7 28 73 60 73 65]\n",
    " [17 73 45  8 27 73 66  8 46 27]\n",
    " [73 17 60 12 73  8 27 28 73 45]\n",
    " [66 64 17 17 46  7 20 73 60 20]\n",
    " [73 76 20 20 60 73  8 60 80 73]\n",
    " [47 35 43  7 20 17 24 50 37 73]]\n",
    "\n",
    "y\n",
    " [[ 8 60 11 45 27 28 73  1  2  2]\n",
    " [ 7 20 73 45  8 60 45 73 60 45]\n",
    " [20 80 73  7 28 73 60 73 65  7]\n",
    " [73 45  8 27 73 66  8 46 27 65]\n",
    " [17 60 12 73  8 27 28 73 45 27]\n",
    " [64 17 17 46  7 20 73 60 20 80]\n",
    " [76 20 20 60 73  8 60 80 73 17]\n",
    " [35 43  7 20 17 24 50 37 73 36]]\n",
    " ```\n",
    " хотя точные цифры могут отличаться. Убедитесь, что данные сдвинуты на один шаг для `y`!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jouxv0L2ceEl"
   },
   "source": [
    "---\n",
    "## Зададим архитектуру\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/udacity/deep-learning-v2-pytorch/blob/master/recurrent-neural-networks/char-rnn/assets/charRNN.png?raw=1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7s5eRaoceEl"
   },
   "source": [
    "### Структура модели\n",
    "\n",
    "В `__init__` предлагаемая структура выглядит следующим образом:\n",
    "* Создаваём и храним необходимые словари (уже релизовано)\n",
    "* Определяем слой LSTM, который принимает в качестве параметров: размер ввода (количество символов), размер скрытого слоя `n_hidden`, количество слоев` n_layers`, вероятность drop-out'а `drop_prob` и логическое значение batch_first (True)\n",
    "* Определяем слой drop-out с помощью drop_prob\n",
    "* Определяем полносвязанный слой с параметрами: размер ввода `n_hidden` и размер выхода - количество символов\n",
    "* Наконец, инициализируем веса\n",
    "\n",
    "Обратите внимание, что некоторые параметры были названы и указаны в функции `__init__`, их нужно сохранить и использовать, выполняя что-то вроде` self.drop_prob = drop_prob`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Plm1atCuceEl"
   },
   "source": [
    "---\n",
    "### Входы-выходы LSTM\n",
    "\n",
    "Вы можете создать [LSTM layer](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM) следующим образом\n",
    "\n",
    "```python\n",
    "self.lstm = nn.LSTM(input_size, n_hidden, n_layers,\n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "```\n",
    "\n",
    "где `input_siz`e - это количество символов, которые эта ячейка ожидает видеть в качестве последовательного ввода, а `n_hidde`n - это количество элементов в скрытых слоях ячейки. Можно добавить drop-out, добавив параметр `dropout` с заданной вероятностью. Наконец, в функции `forward` мы можем складывать ячейки LSTM в слои, используя `.view`.\n",
    "\n",
    "Также требуется создать начальное скрытое состояние всех нулей:\n",
    "\n",
    "```python\n",
    "self.init_hidden()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "HlTnDntHceEl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else:\n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "VPq1EA38rBqn"
   },
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 tokens, # tokens: все уникальные символы (алфавит) в обучающем тексте.\n",
    "                 n_hidden=256, # n_hidden: количество нейронов в скрытых слоях.\n",
    "                                # число нейронов, используемых в каждом скрытом слое LSTM.\n",
    "                                # Эти нейроны участвуют в обработке данных на каждом временном шаге.\n",
    "                                # Как влияет? Большее число нейронов позволяет модели выучивать более сложные зависимости\n",
    "                                # в данных, что особенно важно для работы с длинными последовательностями, такими как текст.\n",
    "                                # Однако слишком большое значение может увеличить время обучения и риск переобучения.\n",
    "                                # Пример: Если мы анализируем текст и пытаемся предсказать следующий символ,большое количество\n",
    "                                # нейронов может помочь лучше учитывать контекст, например, длинные фразы или предложения.\n",
    "                 \n",
    "                 n_layers=2, # n_layers: количество слоев LSTM (Long Short-Term Memory, улучшенная версия RNN,\n",
    "                             # которая лучше запоминает длинные зависимости в тексте).\n",
    "                             # Количество слоев LSTM в модели. Каждый слой добавляет дополнительную \"глубину\",\n",
    "                             # позволяя модели выучивать более сложные паттерны.\n",
    "                             # Как влияет? Увеличение числа слоев может помочь сети обрабатывать данные\n",
    "                             # на разных уровнях абстракции. Например:\n",
    "                             # Нижний слой может анализировать простые связи (например, буквы и слоги).\n",
    "                             # Верхние слои могут анализировать более сложные структуры\n",
    "                             # (например, грамматические конструкции или общий смысл).\n",
    "                             # Но слишком большое количество слоев может привести к \"взрывающемуся\"\n",
    "                             # или \"затухающему\" градиенту, что усложняет обучение.\n",
    "                             # Обычно: 2-3 слоя — это оптимальное число для большинства задач,\n",
    "                             # поскольку оно балансирует сложность и вычислительную эффективность.\n",
    "                 \n",
    "                 drop_prob=0.5, # drop_prob: вероятность \"выключения\" некоторых нейронов (Dropout)\n",
    "                                # для предотвращения переобучения.\n",
    "                                # Dropout — это регуляризационная техника,\n",
    "                                # при которой случайно \"выключается\" определённый процент нейронов во время обучения.\n",
    "                                # Эта вероятность задаётся через параметр drop_prob.\n",
    "                                # Как влияет? Это помогает предотвратить переобучение, заставляя модель искать\n",
    "                                # более обобщённые решения, а не полагаться на конкретные нейроны.\n",
    "                                # Например, если drop_prob = 0.5, то во время каждого шага обучения\n",
    "                                # 50% нейронов будут отключены.\n",
    "                                # Когда использовать? Dropout особенно полезен для глубоких моделей\n",
    "                                # или небольших наборов данных, где переобучение является проблемой.\n",
    "                 \n",
    "                 lr=0.001 # lr: скорость обучения модели.\n",
    "                          # Скорость обучения определяет, насколько сильно обновляются веса нейронной сети во время каждого шага обучения.\n",
    "                          # Как влияет? Маленький lr: Сеть обучается медленно.\n",
    "                          # Может найти более точное решение, но есть риск \"застрять\" в локальном минимуме.\n",
    "                          # Большой lr: Сеть обучается быстро, но есть риск \"проскочить\" оптимальное решение.\n",
    "                          # Обычно: Начинают с небольшого значения (например, 0.001) и корректируют его в процессе,\n",
    "                          # используя адаптивные оптимизаторы (например, Adam, как в коде).\n",
    "\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "\n",
    "        # Словари преобразуют символы в числа (индексы) и наоборот, чтобы модель могла работать с текстом.\n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "\n",
    "        ## TODO: define the LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            len(self.chars), # количество уникальных символов в тексте. Это задает размер входного слоя (input layer).\n",
    "                             # У каждого символа в алфавите будет своё уникальное числовое представление.\n",
    "                             # Например, если алфавит состоит из символов ['a', 'b', 'c', 'd'],\n",
    "                             # то len(self.chars) = 4, и каждый символ будет закодирован как одно из чисел [0, 1, 2, 3].\n",
    "            \n",
    "            n_hidden, # количество нейронов (или размер \"памяти\") в каждом скрытом слое LSTM.\n",
    "                      # Больше нейронов позволяет модели запоминать больше информации о последовательности,\n",
    "                      # что полезно для сложных зависимостей в данных.\n",
    "                      # Однако слишком большое значение увеличивает вычислительные затраты и риск переобучения.\n",
    "                      # Оптимальный размер зависит от задачи: для простого текста может хватить 128-256 нейронов,\n",
    "                      # а для сложных текстов — 512-1024.\n",
    "            \n",
    "            n_layers, # количество последовательных LSTM-слоев в модели.\n",
    "                      # Более глубокие модели (с большим количеством слоев)\n",
    "                      # позволяют лучше обрабатывать сложные зависимости в данных.\n",
    "                      # Однако добавление слоев увеличивает риск затухания или взрыва градиентов\n",
    "                      # (решается использованием Dropout или архитектур, как LSTM/GRU).\n",
    "                      # Чаще всего используется 2-3 слоя, чтобы найти баланс между сложностью модели\n",
    "                      # и вычислительной эффективностью.\n",
    "            \n",
    "            dropout=drop_prob,\n",
    "            batch_first=True # Указывает, что входные данные должны иметь формат [batch_size, seq_length, features], где:\n",
    "                             # batch_size — количество последовательностей в пакете.\n",
    "                             # seq_length — длина каждой последовательности.\n",
    "                             # features — размерность векторов на каждом временном шаге\n",
    "                             # (например, 1, если это последовательность индексов символов).\n",
    "        )\n",
    "\n",
    "        ## Dropout случайным образом \"выключает\" нейроны (устанавливает их выход в 0) с вероятностью drop_prob.\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "\n",
    "        ## TODO: define the final, fully-connected output layer\n",
    "        self.fc = nn.Linear(n_hidden, len(self.chars)) # выходной слой сети,\n",
    "                                                       # который преобразует выход скрытых слоев LSTM (размером n_hidden)\n",
    "                                                       # в распределение вероятностей для каждого символа алфавита.\n",
    "\n",
    "        ## Как это всё работает вместе?\n",
    "        # 1. Входной текст преобразуется в последовательность индексов (длина — seq_length), соответствующих символам алфавита.\n",
    "        # 2. Эти последовательности проходят через LSTM, где каждый временной шаг обновляет скрытое состояние модели.\n",
    "        # Размер скрытого состояния задается параметром n_hidden, а глубина слоев — n_layers.\n",
    "        # 3. На каждом шаге используется Dropout, чтобы случайно \"выключать\" нейроны и улучшать обобщающую способность модели.\n",
    "        # 4. Полносвязный слой преобразует выход скрытых слоев в вероятности для каждого символа алфавита.\n",
    "        # 5. На основе этих вероятностей выбирается следующий символ, который добавляется к последовательности.\n",
    "        # Эта архитектура особенно популярна для задач, связанных с генерацией текста, таких как автозавершение,\n",
    "        # написание стихов или генерация программного кода.\n",
    "\n",
    "    # Forward-проход (прогон данных через модель)\n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network.\n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "\n",
    "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
    "        # Данные (x) проходят через LSTM, который возвращает:\n",
    "            # r_output: выход LSTM для каждого временного шага.\n",
    "            # hidden: новое скрытое состояние, которое нужно сохранить для следующего шага.\n",
    "        r_output, hidden = self.lstm(x, hidden)\n",
    "\n",
    "        ## Выход проходит через слой Dropout\n",
    "        out = self.dropout(r_output)\n",
    "\n",
    "        # Stack up LSTM outputs using view\n",
    "        # you may need to use contiguous to reshape the output\n",
    "        # Выход преобразуется в вероятности для каждого символа с помощью полносвязного слоя:\n",
    "        out = out.contiguous().view(-1, self.n_hidden) # contiguous и view изменяют форму данных для совместимости\n",
    "                                                       # с полносвязным слоем.\n",
    "\n",
    "        ## TODO: put x through the fully-connected layer\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # return the final output and the hidden state\n",
    "        # Модель возвращает:\n",
    "            # out: вероятности символов.\n",
    "            # hidden: обновленное состояние для следующего шага.\n",
    "        return out, hidden\n",
    "\n",
    "    ## Инициализация скрытых состояний\n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        # Создаются тензоры для хранения скрытого состояния (hidden state) и состояния ячейки (cell state) LSTM.\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IrBRlEPceEl"
   },
   "source": [
    "## Обучим модель\n",
    "\n",
    "Во время обучения нужно установить количество эпох, скорость обучения и другие параметры.\n",
    "\n",
    "Используем оптимизатор Adam и кросс-энтропию, считаем loss и, как обычно, выполняем back propagation.\n",
    "\n",
    "Пара подробностей об обучении:\n",
    "> * Во время цикла мы отделяем скрытое состояние от его истории; на этот раз установив его равным новой переменной * tuple *, потому что скрытое состояние LSTM, является кортежем скрытых состояний.\n",
    "* Мы используем [`clip_grad_norm_`](https://pytorch.org/docs/stable/_modules/torch/nn/utils/clip_grad.html) чтобы избавиться от взрывающихся градиентов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Концепция работы модели:\n",
    "1. **Инициализация модели:**\n",
    "    * Класс CharRNN является подклассом PyTorch nn.Module.\n",
    "    * В конструкторе (__init__) определяются параметры модели и слои, такие как:\n",
    "      * LSTM (основной слой, который обрабатывает последовательности символов).\n",
    "      * Dropout (для регуляризации и предотвращения переобучения).\n",
    "      * Полносвязный слой (для преобразования скрытых состояний в вероятности для каждого символа алфавита).\n",
    "    * Также создаются словари (char2int и int2char) для преобразования символов в числовые индексы и обратно.\n",
    "\n",
    "2. **Архитектура модели:**\n",
    "    * LSTM слой обрабатывает последовательности входных данных, состоящих из числовых представлений символов.\n",
    "    * После LSTM используется Dropout для регуляризации.\n",
    "    * Полносвязный слой (self.fc) преобразует выходы LSTM в распределение вероятностей по символам алфавита.\n",
    "\n",
    "3. **Прямой проход (forward):**\n",
    "    * На вход подаются:\n",
    "      * x — входные данные (батч последовательностей символов, закодированных в виде индексов).\n",
    "      * hidden — начальные скрытые состояния LSTM.\n",
    "    * Внутри метода:\n",
    "      * Данные проходят через слой LSTM, который возвращает:\n",
    "          * r_output — выходы LSTM для каждого временного шага.\n",
    "          * Обновленное скрытое состояние hidden.\n",
    "      * Затем применяется Dropout для улучшения обобщающей способности.\n",
    "      * Полносвязный слой преобразует выходы LSTM в вероятности для каждого символа.\n",
    "    * Метод возвращает:\n",
    "      * out — вероятности символов (предсказания модели).\n",
    "      * hidden — скрытое состояние для следующего шага.\n",
    "\n",
    "4. **Инициализация скрытых состояний (init_hidden):**\n",
    "      * Создает начальное скрытое состояние LSTM (нулевые тензоры) для первого прохода.\n",
    "\n",
    "### Основные этапы выполнения кода:\n",
    "1. **Создание экземпляра модели:**\n",
    "    * Модель создается с заданными параметрами (например, количество слоев LSTM, скрытых нейронов, вероятность Dropout).\n",
    "    * Уникальные символы текста (алфавит) передаются в качестве входных данных (tokens).\n",
    "\n",
    "2. **Инициализация скрытых состояний:**\n",
    "    * Перед началом обучения или генерации текста вызывается метод init_hidden, который создает нулевые тензоры для скрытых состояний.\n",
    "\n",
    "3. **Прямой проход через модель (forward):**\n",
    "    * Во время обучения или генерации входная последовательность символов преобразуется в индексы.\n",
    "    * Эти индексы подаются в модель:\n",
    "      * Сначала данные проходят через LSTM, который анализирует временные зависимости.\n",
    "      * Результаты LSTM обрабатываются через Dropout для регуляризации.\n",
    "      * Полносвязный слой преобразует выходы LSTM в вероятности каждого символа.\n",
    "\n",
    "4. **Процесс обучения (описывается в функции train):**\n",
    "    * Модель обучается на батчах данных. На каждом шаге:\n",
    "      * Скрытое состояние инициализируется для текущего батча.\n",
    "      * Батч данных проходит через модель.\n",
    "      * Ошибка рассчитывается на основе разницы между предсказанными и реальными символами.\n",
    "      * Градиенты вычисляются и обновляют веса модели.\n",
    "\n",
    "5. **Генерация текста:**\n",
    "    * После обучения модель может генерировать текст:\n",
    "      * На основе входной строки (seed) предсказываются следующие символы.\n",
    "      * Предсказанные символы добавляются в строку, и процесс повторяется.\n",
    "\n",
    "### Порядок вызова функций:\n",
    "1. **Создание модели:**\n",
    "    * Конструктор __init__ инициализирует слои и параметры модели.\n",
    "\n",
    "2. **Инициализация скрытых состояний:**\n",
    "    * init_hidden вызывается перед началом обработки данных.\n",
    "\n",
    "3. **Обработка данных:**\n",
    "    * На каждом шаге:\n",
    "      * Входные данные подаются в метод forward, где выполняется основной расчет.\n",
    "      * Выходы используются для предсказаний или расчета ошибки.\n",
    "\n",
    "4. **Обновление весов (во время обучения):**\n",
    "    * После каждого шага обучения обновляются веса модели.\n",
    "\n",
    "5. **Использование обученной модели:**\n",
    "    * После обучения модель используется для генерации текста или предсказания символов.\n",
    "\n",
    "### Логика поэтапного выполнения:\n",
    "1. **Токенизация текста:**\n",
    "    * Символы преобразуются в индексы для работы с LSTM.\n",
    "\n",
    "2. **Обработка последовательностей:**\n",
    "    * LSTM анализирует последовательность символов, учитывая контекст предыдущих временных шагов.\n",
    "\n",
    "3. **Предсказание символов:**\n",
    "    * Для каждого шага рассчитываются вероятности следующего символа.\n",
    "\n",
    "4. **Генерация текста:**\n",
    "    * С использованием обученной модели создаются новые последовательности текста, где каждый следующий символ выбирается на основе предсказанных вероятностей.\n",
    "\n",
    "Модель подходит для задач генерации текста, таких как автозавершение или написание текстов в заданном стиле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "lv8VkRI0ceEl"
   },
   "outputs": [],
   "source": [
    "def train(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
    "    ''' Training a network\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "\n",
    "        net: CharRNN network\n",
    "        data: text data to train the network\n",
    "        epochs: Number of epochs to train\n",
    "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
    "        seq_length: Number of character steps per mini-batch\n",
    "        lr: learning rate\n",
    "        clip: gradient clipping\n",
    "        val_frac: Fraction of data to hold out for validation\n",
    "        print_every: Number of steps for printing training and validation loss\n",
    "\n",
    "    '''\n",
    "    # 1. epochs — количество эпох. Эпоха — это полный проход по всему тренировочному набору данных (или его батчам).\n",
    "    # Чем больше эпох, тем больше времени модель обучается на данных. Это позволяет ей лучше находить закономерности.\n",
    "    # Однако слишком много эпох может привести к переобучению, когда модель начинает \"запоминать\" данные вместо того,\n",
    "    # чтобы учиться обобщать. Нужно экспериментировать, чтобы найти оптимальное количество эпох.\n",
    "    # Иногда удобно использовать Early Stopping, чтобы остановить обучение,\n",
    "    # когда ошибка на валидационной выборке перестает снижаться.\n",
    "    \n",
    "    # 1. Почему одной эпохи недостаточно? За одну эпоху:\n",
    "        # Модель видит каждый пример из датасета только один раз.\n",
    "        # На этом этапе веса модели обновляются, но она еще не успевает выучить все особенности данных,\n",
    "        # особенно если датасет сложный или большой.\n",
    "        # Реальная модель учится постепенно, с каждым проходом улучшая свои предсказания.\n",
    "        # Первая эпоха — это своего рода «разминка».\n",
    "\n",
    "    # 2. Как работают несколько эпох? Каждая новая эпоха:\n",
    "        # Использует обновленные веса модели с предыдущей эпохи.\n",
    "        # Углубляет обучение: за счет постепенного уменьшения ошибки (loss), модель становится более точной.\n",
    "        # Пример: В первую эпоху модель может выучить базовые паттерны, например:\n",
    "        # \"слово 'люблю' чаще встречается в позитивных текстах\".\n",
    "        # Во вторую эпоху она может начать учитывать более сложные зависимости,\n",
    "        # например: \"если 'люблю' стоит в отрицательном контексте ('не люблю'), то текст становится негативным\".\n",
    "        # В последующих эпохах модель уточняет свои предсказания и учится лучше обрабатывать сложные случаи.\n",
    "    \n",
    "    # 3. Что произойдет, если сделать всего 1 эпоху? Если остановиться после одной эпохи:\n",
    "        # Модель может быть недообученной: она еще не успеет выучить все важные зависимости.\n",
    "        # Ошибка (loss) на тестовых данных, скорее всего, останется высокой.\n",
    "        # Это особенно критично на больших или сложных датасетах, где обучаться за одну эпоху просто невозможно.\n",
    "    \n",
    "    # 4. Сколько эпох нужно? Количество эпох зависит от:\n",
    "        # Сложности задачи: Простые задачи требуют меньше эпох, сложные — больше.\n",
    "        # Размеров датасета: Чем больше данных, тем больше времени нужно для обучения.\n",
    "        # Переобучение: Если продолжать обучение слишком долго, модель начнет \"зазубривать\" данные,\n",
    "        # что ухудшит её работу на новых данных.\n",
    "        # Часто используется Early Stopping: обучение останавливается,\n",
    "        # как только ошибка на валидационной выборке перестает уменьшаться.\n",
    "\n",
    "    # 5. Пример с аналогией. Представь, что ты учишься готовить по новому рецепту:\n",
    "        # Первая эпоха: Ты прочитал рецепт, попробовал приготовить блюдо. Получилось, но не идеально.\n",
    "        # Вторая эпоха: Ты учел свои ошибки с первого раза (например, меньше соли, больше масла) и приготовил блюдо лучше.\n",
    "        # Третья эпоха: Ты уже помнишь рецепт, понимаешь нюансы, и блюдо становится практически идеальным.\n",
    "    \n",
    "    # 2. batch_size — размер батча. Это количество примеров данных, которые обрабатываются моделью одновременно\n",
    "    # перед обновлением весов. Маленькие батчи позволяют модели быстрее обновлять веса,\n",
    "    # но могут приводить к шумным обновлениям (нестабильность градиента).\n",
    "    # Большие батчи дают более стабильное обучение, но требуют больше памяти и времени для обработки.\n",
    "    # Для небольших моделей можно использовать значения в диапазоне 32–128, а для более сложных задач — до 256–512,\n",
    "    # если позволяет память.\n",
    "    \n",
    "    # 3. seq_length — длина последовательности символов. Это количество символов,\n",
    "    # обрабатываемых моделью за один раз (последовательность временных шагов). Длинные последовательности позволяют модели\n",
    "    # учитывать больше контекста, что важно для задач, где порядок символов критичен (например, генерация текста).\n",
    "    # Слишком длинные последовательности могут замедлить обучение и увеличить требования к памяти.\n",
    "    # Для текстов длиной 50-100 символов часто хватает seq_length = 100. Если текст имеет сложные долгосрочные зависимости,\n",
    "    # длину можно увеличить.\n",
    "    \n",
    "    # 4. lr — скорость обучения\n",
    "    # Скорость обучения (learning rate) определяет размер шага, с которым модель обновляет свои веса после вычисления градиента.\n",
    "    # Слишком маленький lr приводит к медленному обучению, и модель может застрять в локальном минимуме.\n",
    "    # Слишком большой lr может привести к пропуску минимума или нестабильности модели (разброс весов).\n",
    "    # Обычно начинают с значения 0.001 или 0.01. Если модель не сходится, можно уменьшить lr.\n",
    "    # Также популярны адаптивные методы, такие как Adam или SGD с динамическим изменением скорости обучения.\n",
    "    \n",
    "    # 5. clip — обрезка градиентов\n",
    "    # Ограничение максимального значения градиентов до определенного порога.\n",
    "    # В задачах с последовательностями (например, LSTM) градиенты могут стать очень большими (взрыв градиентов).\n",
    "    # Это приводит к нестабильности и невозможности корректно обновлять веса.\n",
    "    # Обрезка градиентов (gradient clipping) помогает стабилизировать процесс обучения, обрезая градиенты,\n",
    "    # если они превышают заданное значение.\n",
    "    # Часто используют значения 1.0 или 5.0. Эти значения нужно тестировать для конкретной задачи.\n",
    "    \n",
    "    # 6. val_frac — доля данных для проверки\n",
    "    # Это часть данных, выделяемая для проверки (валидации), чтобы оценить, как хорошо модель обобщает данные.\n",
    "    # Валидация позволяет понять, переобучается ли модель. Если ошибка на тренировочной выборке падает,\n",
    "    # а на валидационной — растет, значит, модель начинает \"запоминать\" данные.\n",
    "    # Обычно для валидации выделяют 10–20% от всех данных (то есть val_frac = 0.1 или 0.2).\n",
    "    \n",
    "    # Как все эти параметры работают вместе?\n",
    "    # epochs и batch_size: Определяют, как долго и с каким количеством данных за раз модель будет обучаться. Например,\n",
    "    # 10 эпох при batch_size=32 означают, что модель сделает 10 проходов по всему датасету, обрабатывая по 32 примера за раз.\n",
    "    # seq_length: Влияет на то, сколько контекста модель учитывает за один временной шаг.\n",
    "    # Длинные последовательности улучшают способность модели понимать связи между символами, но требуют больше ресурсов.\n",
    "    # lr и clip: Управляют процессом обновления весов.\n",
    "    # Правильная настройка скорости обучения и обрезки градиентов гарантируетстабильное обучение без разрывов.\n",
    "    # val_frac: Позволяет отслеживать качество модели и избегать переобучения. Модель обучается на 80–90% данных,\n",
    "    # а оставшиеся 10–20% используются для проверки.\n",
    "    # Эти гиперпараметры взаимодействуют друг с другом, и их настройка зависит от задачи, размера данных и архитектуры модели.\n",
    "    \n",
    "    net.train()\n",
    "\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # create training and validation data\n",
    "    val_idx = int(len(data)*(1-val_frac))\n",
    "    data, val_data = data[:val_idx], data[val_idx:]\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "\n",
    "    counter = 0\n",
    "    n_chars = len(net.chars)\n",
    "    for e in range(epochs):\n",
    "        # initialize hidden state\n",
    "        h = net.init_hidden(batch_size)\n",
    "\n",
    "        for x, y in get_batches(data, batch_size, seq_length):\n",
    "            counter += 1\n",
    "\n",
    "            # One-hot encode our data and make them Torch tensors\n",
    "            x = one_hot_encode(x, n_chars)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "            if(train_on_gpu):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "\n",
    "            # get the output from the model\n",
    "            output, h = net(inputs, h)\n",
    "\n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            opt.step()\n",
    "\n",
    "            # loss stats\n",
    "            if counter % print_every == 0:\n",
    "                # Get validation loss\n",
    "                val_h = net.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                net.eval()\n",
    "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
    "                    # One-hot encode our data and make them Torch tensors\n",
    "                    x = one_hot_encode(x, n_chars)\n",
    "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "                    # Creating new variables for the hidden state, otherwise\n",
    "                    # we'd backprop through the entire training history\n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                    inputs, targets = x, y\n",
    "                    if(train_on_gpu):\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                    output, val_h = net(inputs, val_h)\n",
    "                    val_loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
    "\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "                net.train() # reset to train mode after iterationg through validation data\n",
    "\n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gt0q4KGEceEm"
   },
   "source": [
    "## Определим модель\n",
    "\n",
    "Теперь мы можем создать модель с заданными гиперпараметрами. Определим размеры мини-батчей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ykMcIloEr3G7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharRNN(\n",
      "  (lstm): LSTM(83, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=83, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define and print the net\n",
    "n_hidden=512\n",
    "n_layers=2\n",
    "\n",
    "net = CharRNN(chars, n_hidden, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHy6mECuceEm"
   },
   "source": [
    "### Установим гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "soEszcw6Ey6y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Step: 10... Loss: 3.2507... Val Loss: 3.1666\n",
      "Epoch: 1/20... Step: 20... Loss: 3.1414... Val Loss: 3.1284\n",
      "Epoch: 1/20... Step: 30... Loss: 3.1414... Val Loss: 3.1211\n",
      "Epoch: 1/20... Step: 40... Loss: 3.1118... Val Loss: 3.1198\n",
      "Epoch: 1/20... Step: 50... Loss: 3.1411... Val Loss: 3.1165\n",
      "Epoch: 1/20... Step: 60... Loss: 3.1167... Val Loss: 3.1131\n",
      "Epoch: 1/20... Step: 70... Loss: 3.1004... Val Loss: 3.1073\n",
      "Epoch: 1/20... Step: 80... Loss: 3.1034... Val Loss: 3.0913\n",
      "Epoch: 1/20... Step: 90... Loss: 3.0755... Val Loss: 3.0564\n",
      "Epoch: 1/20... Step: 100... Loss: 2.9982... Val Loss: 2.9680\n",
      "Epoch: 1/20... Step: 110... Loss: 2.9094... Val Loss: 2.8839\n",
      "Epoch: 1/20... Step: 120... Loss: 2.8302... Val Loss: 2.7881\n",
      "Epoch: 1/20... Step: 130... Loss: 2.7085... Val Loss: 2.6661\n",
      "Epoch: 2/20... Step: 140... Loss: 2.6329... Val Loss: 2.5710\n",
      "Epoch: 2/20... Step: 150... Loss: 2.5692... Val Loss: 2.5286\n",
      "Epoch: 2/20... Step: 160... Loss: 2.5142... Val Loss: 2.4773\n",
      "Epoch: 2/20... Step: 170... Loss: 2.4636... Val Loss: 2.4455\n",
      "Epoch: 2/20... Step: 180... Loss: 2.4172... Val Loss: 2.4051\n",
      "Epoch: 2/20... Step: 190... Loss: 2.3668... Val Loss: 2.3647\n",
      "Epoch: 2/20... Step: 200... Loss: 2.3662... Val Loss: 2.3343\n",
      "Epoch: 2/20... Step: 210... Loss: 2.3331... Val Loss: 2.3069\n",
      "Epoch: 2/20... Step: 220... Loss: 2.3012... Val Loss: 2.2763\n",
      "Epoch: 2/20... Step: 230... Loss: 2.2851... Val Loss: 2.2526\n",
      "Epoch: 2/20... Step: 240... Loss: 2.2659... Val Loss: 2.2265\n",
      "Epoch: 2/20... Step: 250... Loss: 2.1967... Val Loss: 2.2039\n",
      "Epoch: 2/20... Step: 260... Loss: 2.1783... Val Loss: 2.1754\n",
      "Epoch: 2/20... Step: 270... Loss: 2.1955... Val Loss: 2.1610\n",
      "Epoch: 3/20... Step: 280... Loss: 2.1889... Val Loss: 2.1342\n",
      "Epoch: 3/20... Step: 290... Loss: 2.1508... Val Loss: 2.1101\n",
      "Epoch: 3/20... Step: 300... Loss: 2.1275... Val Loss: 2.0929\n",
      "Epoch: 3/20... Step: 310... Loss: 2.0980... Val Loss: 2.0793\n",
      "Epoch: 3/20... Step: 320... Loss: 2.0752... Val Loss: 2.0575\n",
      "Epoch: 3/20... Step: 330... Loss: 2.0408... Val Loss: 2.0408\n",
      "Epoch: 3/20... Step: 340... Loss: 2.0705... Val Loss: 2.0209\n",
      "Epoch: 3/20... Step: 350... Loss: 2.0539... Val Loss: 2.0040\n",
      "Epoch: 3/20... Step: 360... Loss: 1.9747... Val Loss: 1.9886\n",
      "Epoch: 3/20... Step: 370... Loss: 2.0196... Val Loss: 1.9730\n",
      "Epoch: 3/20... Step: 380... Loss: 1.9863... Val Loss: 1.9567\n",
      "Epoch: 3/20... Step: 390... Loss: 1.9578... Val Loss: 1.9444\n",
      "Epoch: 3/20... Step: 400... Loss: 1.9305... Val Loss: 1.9353\n",
      "Epoch: 3/20... Step: 410... Loss: 1.9419... Val Loss: 1.9163\n",
      "Epoch: 4/20... Step: 420... Loss: 1.9417... Val Loss: 1.9044\n",
      "Epoch: 4/20... Step: 430... Loss: 1.9207... Val Loss: 1.8874\n",
      "Epoch: 4/20... Step: 440... Loss: 1.9103... Val Loss: 1.8803\n",
      "Epoch: 4/20... Step: 450... Loss: 1.8492... Val Loss: 1.8611\n",
      "Epoch: 4/20... Step: 460... Loss: 1.8407... Val Loss: 1.8541\n",
      "Epoch: 4/20... Step: 470... Loss: 1.8734... Val Loss: 1.8404\n",
      "Epoch: 4/20... Step: 480... Loss: 1.8568... Val Loss: 1.8305\n",
      "Epoch: 4/20... Step: 490... Loss: 1.8551... Val Loss: 1.8228\n",
      "Epoch: 4/20... Step: 500... Loss: 1.8589... Val Loss: 1.8107\n",
      "Epoch: 4/20... Step: 510... Loss: 1.8235... Val Loss: 1.7990\n",
      "Epoch: 4/20... Step: 520... Loss: 1.8425... Val Loss: 1.7863\n",
      "Epoch: 4/20... Step: 530... Loss: 1.7963... Val Loss: 1.7808\n",
      "Epoch: 4/20... Step: 540... Loss: 1.7648... Val Loss: 1.7664\n",
      "Epoch: 4/20... Step: 550... Loss: 1.8071... Val Loss: 1.7581\n",
      "Epoch: 5/20... Step: 560... Loss: 1.7790... Val Loss: 1.7469\n",
      "Epoch: 5/20... Step: 570... Loss: 1.7609... Val Loss: 1.7366\n",
      "Epoch: 5/20... Step: 580... Loss: 1.7281... Val Loss: 1.7370\n",
      "Epoch: 5/20... Step: 590... Loss: 1.7379... Val Loss: 1.7224\n",
      "Epoch: 5/20... Step: 600... Loss: 1.7312... Val Loss: 1.7158\n",
      "Epoch: 5/20... Step: 610... Loss: 1.7103... Val Loss: 1.7105\n",
      "Epoch: 5/20... Step: 620... Loss: 1.7184... Val Loss: 1.7031\n",
      "Epoch: 5/20... Step: 630... Loss: 1.7328... Val Loss: 1.6926\n",
      "Epoch: 5/20... Step: 640... Loss: 1.7024... Val Loss: 1.6838\n",
      "Epoch: 5/20... Step: 650... Loss: 1.6862... Val Loss: 1.6789\n",
      "Epoch: 5/20... Step: 660... Loss: 1.6648... Val Loss: 1.6694\n",
      "Epoch: 5/20... Step: 670... Loss: 1.6874... Val Loss: 1.6671\n",
      "Epoch: 5/20... Step: 680... Loss: 1.6841... Val Loss: 1.6563\n",
      "Epoch: 5/20... Step: 690... Loss: 1.6601... Val Loss: 1.6536\n",
      "Epoch: 6/20... Step: 700... Loss: 1.6661... Val Loss: 1.6483\n",
      "Epoch: 6/20... Step: 710... Loss: 1.6500... Val Loss: 1.6367\n",
      "Epoch: 6/20... Step: 720... Loss: 1.6377... Val Loss: 1.6326\n",
      "Epoch: 6/20... Step: 730... Loss: 1.6494... Val Loss: 1.6256\n",
      "Epoch: 6/20... Step: 740... Loss: 1.6179... Val Loss: 1.6236\n",
      "Epoch: 6/20... Step: 750... Loss: 1.5942... Val Loss: 1.6179\n",
      "Epoch: 6/20... Step: 760... Loss: 1.6388... Val Loss: 1.6100\n",
      "Epoch: 6/20... Step: 770... Loss: 1.6202... Val Loss: 1.6088\n",
      "Epoch: 6/20... Step: 780... Loss: 1.5929... Val Loss: 1.5973\n",
      "Epoch: 6/20... Step: 790... Loss: 1.5893... Val Loss: 1.5948\n",
      "Epoch: 6/20... Step: 800... Loss: 1.6036... Val Loss: 1.5919\n",
      "Epoch: 6/20... Step: 810... Loss: 1.5934... Val Loss: 1.5870\n",
      "Epoch: 6/20... Step: 820... Loss: 1.5568... Val Loss: 1.5795\n",
      "Epoch: 6/20... Step: 830... Loss: 1.6017... Val Loss: 1.5725\n",
      "Epoch: 7/20... Step: 840... Loss: 1.5588... Val Loss: 1.5683\n",
      "Epoch: 7/20... Step: 850... Loss: 1.5775... Val Loss: 1.5624\n",
      "Epoch: 7/20... Step: 860... Loss: 1.5570... Val Loss: 1.5612\n",
      "Epoch: 7/20... Step: 870... Loss: 1.5600... Val Loss: 1.5528\n",
      "Epoch: 7/20... Step: 880... Loss: 1.5679... Val Loss: 1.5506\n",
      "Epoch: 7/20... Step: 890... Loss: 1.5596... Val Loss: 1.5470\n",
      "Epoch: 7/20... Step: 900... Loss: 1.5397... Val Loss: 1.5425\n",
      "Epoch: 7/20... Step: 910... Loss: 1.5149... Val Loss: 1.5392\n",
      "Epoch: 7/20... Step: 920... Loss: 1.5363... Val Loss: 1.5363\n",
      "Epoch: 7/20... Step: 930... Loss: 1.5281... Val Loss: 1.5317\n",
      "Epoch: 7/20... Step: 940... Loss: 1.5311... Val Loss: 1.5303\n",
      "Epoch: 7/20... Step: 950... Loss: 1.5380... Val Loss: 1.5248\n",
      "Epoch: 7/20... Step: 960... Loss: 1.5398... Val Loss: 1.5236\n",
      "Epoch: 7/20... Step: 970... Loss: 1.5398... Val Loss: 1.5149\n",
      "Epoch: 8/20... Step: 980... Loss: 1.5138... Val Loss: 1.5130\n",
      "Epoch: 8/20... Step: 990... Loss: 1.5203... Val Loss: 1.5077\n",
      "Epoch: 8/20... Step: 1000... Loss: 1.5060... Val Loss: 1.5047\n",
      "Epoch: 8/20... Step: 1010... Loss: 1.5343... Val Loss: 1.5044\n",
      "Epoch: 8/20... Step: 1020... Loss: 1.5115... Val Loss: 1.4997\n",
      "Epoch: 8/20... Step: 1030... Loss: 1.4961... Val Loss: 1.4951\n",
      "Epoch: 8/20... Step: 1040... Loss: 1.5067... Val Loss: 1.4990\n",
      "Epoch: 8/20... Step: 1050... Loss: 1.4910... Val Loss: 1.4907\n",
      "Epoch: 8/20... Step: 1060... Loss: 1.4930... Val Loss: 1.4880\n",
      "Epoch: 8/20... Step: 1070... Loss: 1.4844... Val Loss: 1.4854\n",
      "Epoch: 8/20... Step: 1080... Loss: 1.4880... Val Loss: 1.4848\n",
      "Epoch: 8/20... Step: 1090... Loss: 1.4768... Val Loss: 1.4820\n",
      "Epoch: 8/20... Step: 1100... Loss: 1.4628... Val Loss: 1.4759\n",
      "Epoch: 8/20... Step: 1110... Loss: 1.4740... Val Loss: 1.4720\n",
      "Epoch: 9/20... Step: 1120... Loss: 1.4779... Val Loss: 1.4737\n",
      "Epoch: 9/20... Step: 1130... Loss: 1.4835... Val Loss: 1.4658\n",
      "Epoch: 9/20... Step: 1140... Loss: 1.4849... Val Loss: 1.4591\n",
      "Epoch: 9/20... Step: 1150... Loss: 1.4915... Val Loss: 1.4615\n",
      "Epoch: 9/20... Step: 1160... Loss: 1.4516... Val Loss: 1.4618\n",
      "Epoch: 9/20... Step: 1170... Loss: 1.4560... Val Loss: 1.4558\n",
      "Epoch: 9/20... Step: 1180... Loss: 1.4503... Val Loss: 1.4572\n",
      "Epoch: 9/20... Step: 1190... Loss: 1.4748... Val Loss: 1.4525\n",
      "Epoch: 9/20... Step: 1200... Loss: 1.4305... Val Loss: 1.4497\n",
      "Epoch: 9/20... Step: 1210... Loss: 1.4440... Val Loss: 1.4486\n",
      "Epoch: 9/20... Step: 1220... Loss: 1.4319... Val Loss: 1.4459\n",
      "Epoch: 9/20... Step: 1230... Loss: 1.4169... Val Loss: 1.4410\n",
      "Epoch: 9/20... Step: 1240... Loss: 1.4214... Val Loss: 1.4397\n",
      "Epoch: 9/20... Step: 1250... Loss: 1.4400... Val Loss: 1.4359\n",
      "Epoch: 10/20... Step: 1260... Loss: 1.4327... Val Loss: 1.4320\n",
      "Epoch: 10/20... Step: 1270... Loss: 1.4297... Val Loss: 1.4326\n",
      "Epoch: 10/20... Step: 1280... Loss: 1.4432... Val Loss: 1.4274\n",
      "Epoch: 10/20... Step: 1290... Loss: 1.4417... Val Loss: 1.4295\n",
      "Epoch: 10/20... Step: 1300... Loss: 1.4240... Val Loss: 1.4262\n",
      "Epoch: 10/20... Step: 1310... Loss: 1.4355... Val Loss: 1.4237\n",
      "Epoch: 10/20... Step: 1320... Loss: 1.4024... Val Loss: 1.4292\n",
      "Epoch: 10/20... Step: 1330... Loss: 1.4013... Val Loss: 1.4216\n",
      "Epoch: 10/20... Step: 1340... Loss: 1.3932... Val Loss: 1.4226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/20... Step: 1350... Loss: 1.3860... Val Loss: 1.4163\n",
      "Epoch: 10/20... Step: 1360... Loss: 1.3937... Val Loss: 1.4184\n",
      "Epoch: 10/20... Step: 1370... Loss: 1.3853... Val Loss: 1.4158\n",
      "Epoch: 10/20... Step: 1380... Loss: 1.4261... Val Loss: 1.4127\n",
      "Epoch: 10/20... Step: 1390... Loss: 1.4330... Val Loss: 1.4098\n",
      "Epoch: 11/20... Step: 1400... Loss: 1.4342... Val Loss: 1.4086\n",
      "Epoch: 11/20... Step: 1410... Loss: 1.4437... Val Loss: 1.4056\n",
      "Epoch: 11/20... Step: 1420... Loss: 1.4258... Val Loss: 1.4032\n",
      "Epoch: 11/20... Step: 1430... Loss: 1.3984... Val Loss: 1.4067\n",
      "Epoch: 11/20... Step: 1440... Loss: 1.4186... Val Loss: 1.4026\n",
      "Epoch: 11/20... Step: 1450... Loss: 1.3520... Val Loss: 1.4033\n",
      "Epoch: 11/20... Step: 1460... Loss: 1.3676... Val Loss: 1.3994\n",
      "Epoch: 11/20... Step: 1470... Loss: 1.3663... Val Loss: 1.3984\n",
      "Epoch: 11/20... Step: 1480... Loss: 1.3834... Val Loss: 1.3946\n",
      "Epoch: 11/20... Step: 1490... Loss: 1.3825... Val Loss: 1.3923\n",
      "Epoch: 11/20... Step: 1500... Loss: 1.3674... Val Loss: 1.3952\n",
      "Epoch: 11/20... Step: 1510... Loss: 1.3524... Val Loss: 1.3956\n",
      "Epoch: 11/20... Step: 1520... Loss: 1.3777... Val Loss: 1.3873\n",
      "Epoch: 12/20... Step: 1530... Loss: 1.4426... Val Loss: 1.3879\n",
      "Epoch: 12/20... Step: 1540... Loss: 1.3897... Val Loss: 1.3871\n",
      "Epoch: 12/20... Step: 1550... Loss: 1.3943... Val Loss: 1.3868\n",
      "Epoch: 12/20... Step: 1560... Loss: 1.4099... Val Loss: 1.3809\n",
      "Epoch: 12/20... Step: 1570... Loss: 1.3514... Val Loss: 1.3807\n",
      "Epoch: 12/20... Step: 1580... Loss: 1.3390... Val Loss: 1.3802\n",
      "Epoch: 12/20... Step: 1590... Loss: 1.3316... Val Loss: 1.3820\n",
      "Epoch: 12/20... Step: 1600... Loss: 1.3570... Val Loss: 1.3808\n",
      "Epoch: 12/20... Step: 1610... Loss: 1.3501... Val Loss: 1.3790\n",
      "Epoch: 12/20... Step: 1620... Loss: 1.3460... Val Loss: 1.3758\n",
      "Epoch: 12/20... Step: 1630... Loss: 1.3675... Val Loss: 1.3730\n",
      "Epoch: 12/20... Step: 1640... Loss: 1.3390... Val Loss: 1.3762\n",
      "Epoch: 12/20... Step: 1650... Loss: 1.3205... Val Loss: 1.3727\n",
      "Epoch: 12/20... Step: 1660... Loss: 1.3758... Val Loss: 1.3677\n",
      "Epoch: 13/20... Step: 1670... Loss: 1.3368... Val Loss: 1.3693\n",
      "Epoch: 13/20... Step: 1680... Loss: 1.3459... Val Loss: 1.3648\n",
      "Epoch: 13/20... Step: 1690... Loss: 1.3283... Val Loss: 1.3614\n",
      "Epoch: 13/20... Step: 1700... Loss: 1.3303... Val Loss: 1.3607\n",
      "Epoch: 13/20... Step: 1710... Loss: 1.3154... Val Loss: 1.3653\n",
      "Epoch: 13/20... Step: 1720... Loss: 1.3206... Val Loss: 1.3599\n",
      "Epoch: 13/20... Step: 1730... Loss: 1.3510... Val Loss: 1.3611\n",
      "Epoch: 13/20... Step: 1740... Loss: 1.3376... Val Loss: 1.3584\n",
      "Epoch: 13/20... Step: 1750... Loss: 1.2985... Val Loss: 1.3598\n",
      "Epoch: 13/20... Step: 1760... Loss: 1.3230... Val Loss: 1.3526\n",
      "Epoch: 13/20... Step: 1770... Loss: 1.3402... Val Loss: 1.3505\n",
      "Epoch: 13/20... Step: 1780... Loss: 1.3125... Val Loss: 1.3493\n",
      "Epoch: 13/20... Step: 1790... Loss: 1.3048... Val Loss: 1.3484\n",
      "Epoch: 13/20... Step: 1800... Loss: 1.3253... Val Loss: 1.3441\n",
      "Epoch: 14/20... Step: 1810... Loss: 1.3256... Val Loss: 1.3541\n",
      "Epoch: 14/20... Step: 1820... Loss: 1.3114... Val Loss: 1.3423\n",
      "Epoch: 14/20... Step: 1830... Loss: 1.3371... Val Loss: 1.3407\n",
      "Epoch: 14/20... Step: 1840... Loss: 1.2756... Val Loss: 1.3400\n",
      "Epoch: 14/20... Step: 1850... Loss: 1.2583... Val Loss: 1.3399\n",
      "Epoch: 14/20... Step: 1860... Loss: 1.3186... Val Loss: 1.3455\n",
      "Epoch: 14/20... Step: 1870... Loss: 1.3253... Val Loss: 1.3386\n",
      "Epoch: 14/20... Step: 1880... Loss: 1.3161... Val Loss: 1.3386\n",
      "Epoch: 14/20... Step: 1890... Loss: 1.3300... Val Loss: 1.3365\n",
      "Epoch: 14/20... Step: 1900... Loss: 1.3038... Val Loss: 1.3347\n",
      "Epoch: 14/20... Step: 1910... Loss: 1.3072... Val Loss: 1.3361\n",
      "Epoch: 14/20... Step: 1920... Loss: 1.3040... Val Loss: 1.3341\n",
      "Epoch: 14/20... Step: 1930... Loss: 1.2667... Val Loss: 1.3318\n",
      "Epoch: 14/20... Step: 1940... Loss: 1.3279... Val Loss: 1.3340\n",
      "Epoch: 15/20... Step: 1950... Loss: 1.2974... Val Loss: 1.3344\n",
      "Epoch: 15/20... Step: 1960... Loss: 1.2976... Val Loss: 1.3251\n",
      "Epoch: 15/20... Step: 1970... Loss: 1.2955... Val Loss: 1.3231\n",
      "Epoch: 15/20... Step: 1980... Loss: 1.2865... Val Loss: 1.3294\n",
      "Epoch: 15/20... Step: 1990... Loss: 1.2863... Val Loss: 1.3237\n",
      "Epoch: 15/20... Step: 2000... Loss: 1.2631... Val Loss: 1.3258\n",
      "Epoch: 15/20... Step: 2010... Loss: 1.2776... Val Loss: 1.3250\n",
      "Epoch: 15/20... Step: 2020... Loss: 1.3075... Val Loss: 1.3270\n",
      "Epoch: 15/20... Step: 2030... Loss: 1.2672... Val Loss: 1.3264\n",
      "Epoch: 15/20... Step: 2040... Loss: 1.2915... Val Loss: 1.3166\n",
      "Epoch: 15/20... Step: 2050... Loss: 1.2716... Val Loss: 1.3157\n",
      "Epoch: 15/20... Step: 2060... Loss: 1.2803... Val Loss: 1.3192\n",
      "Epoch: 15/20... Step: 2070... Loss: 1.2907... Val Loss: 1.3136\n",
      "Epoch: 15/20... Step: 2080... Loss: 1.2802... Val Loss: 1.3143\n",
      "Epoch: 16/20... Step: 2090... Loss: 1.2932... Val Loss: 1.3173\n",
      "Epoch: 16/20... Step: 2100... Loss: 1.2730... Val Loss: 1.3133\n",
      "Epoch: 16/20... Step: 2110... Loss: 1.2657... Val Loss: 1.3111\n",
      "Epoch: 16/20... Step: 2120... Loss: 1.2773... Val Loss: 1.3164\n",
      "Epoch: 16/20... Step: 2130... Loss: 1.2572... Val Loss: 1.3096\n",
      "Epoch: 16/20... Step: 2140... Loss: 1.2584... Val Loss: 1.3089\n",
      "Epoch: 16/20... Step: 2150... Loss: 1.2794... Val Loss: 1.3103\n",
      "Epoch: 16/20... Step: 2160... Loss: 1.2595... Val Loss: 1.3088\n",
      "Epoch: 16/20... Step: 2170... Loss: 1.2566... Val Loss: 1.3077\n",
      "Epoch: 16/20... Step: 2180... Loss: 1.2595... Val Loss: 1.3105\n",
      "Epoch: 16/20... Step: 2190... Loss: 1.2886... Val Loss: 1.3067\n",
      "Epoch: 16/20... Step: 2200... Loss: 1.2622... Val Loss: 1.3072\n",
      "Epoch: 16/20... Step: 2210... Loss: 1.2278... Val Loss: 1.3072\n",
      "Epoch: 16/20... Step: 2220... Loss: 1.2796... Val Loss: 1.3065\n",
      "Epoch: 17/20... Step: 2230... Loss: 1.2471... Val Loss: 1.3050\n",
      "Epoch: 17/20... Step: 2240... Loss: 1.2622... Val Loss: 1.3029\n",
      "Epoch: 17/20... Step: 2250... Loss: 1.2470... Val Loss: 1.3025\n",
      "Epoch: 17/20... Step: 2260... Loss: 1.2550... Val Loss: 1.3047\n",
      "Epoch: 17/20... Step: 2270... Loss: 1.2626... Val Loss: 1.3036\n",
      "Epoch: 17/20... Step: 2280... Loss: 1.2633... Val Loss: 1.3097\n",
      "Epoch: 17/20... Step: 2290... Loss: 1.2587... Val Loss: 1.3043\n",
      "Epoch: 17/20... Step: 2300... Loss: 1.2215... Val Loss: 1.3037\n",
      "Epoch: 17/20... Step: 2310... Loss: 1.2435... Val Loss: 1.3018\n",
      "Epoch: 17/20... Step: 2320... Loss: 1.2373... Val Loss: 1.2954\n",
      "Epoch: 17/20... Step: 2330... Loss: 1.2397... Val Loss: 1.2968\n",
      "Epoch: 17/20... Step: 2340... Loss: 1.2589... Val Loss: 1.2931\n",
      "Epoch: 17/20... Step: 2350... Loss: 1.2528... Val Loss: 1.2924\n",
      "Epoch: 17/20... Step: 2360... Loss: 1.2612... Val Loss: 1.2973\n",
      "Epoch: 18/20... Step: 2370... Loss: 1.2299... Val Loss: 1.2912\n",
      "Epoch: 18/20... Step: 2380... Loss: 1.2372... Val Loss: 1.2897\n",
      "Epoch: 18/20... Step: 2390... Loss: 1.2405... Val Loss: 1.2905\n",
      "Epoch: 18/20... Step: 2400... Loss: 1.2707... Val Loss: 1.2934\n",
      "Epoch: 18/20... Step: 2410... Loss: 1.2537... Val Loss: 1.2894\n",
      "Epoch: 18/20... Step: 2420... Loss: 1.2375... Val Loss: 1.2877\n",
      "Epoch: 18/20... Step: 2430... Loss: 1.2399... Val Loss: 1.2905\n",
      "Epoch: 18/20... Step: 2440... Loss: 1.2209... Val Loss: 1.2921\n",
      "Epoch: 18/20... Step: 2450... Loss: 1.2258... Val Loss: 1.2848\n",
      "Epoch: 18/20... Step: 2460... Loss: 1.2391... Val Loss: 1.2925\n",
      "Epoch: 18/20... Step: 2470... Loss: 1.2335... Val Loss: 1.2904\n",
      "Epoch: 18/20... Step: 2480... Loss: 1.2146... Val Loss: 1.2889\n",
      "Epoch: 18/20... Step: 2490... Loss: 1.2218... Val Loss: 1.2853\n",
      "Epoch: 18/20... Step: 2500... Loss: 1.2313... Val Loss: 1.2893\n",
      "Epoch: 19/20... Step: 2510... Loss: 1.2237... Val Loss: 1.2881\n",
      "Epoch: 19/20... Step: 2520... Loss: 1.2441... Val Loss: 1.2891\n",
      "Epoch: 19/20... Step: 2530... Loss: 1.2460... Val Loss: 1.2836\n",
      "Epoch: 19/20... Step: 2540... Loss: 1.2571... Val Loss: 1.2868\n",
      "Epoch: 19/20... Step: 2550... Loss: 1.2198... Val Loss: 1.2830\n",
      "Epoch: 19/20... Step: 2560... Loss: 1.2290... Val Loss: 1.2830\n",
      "Epoch: 19/20... Step: 2570... Loss: 1.2160... Val Loss: 1.2865\n",
      "Epoch: 19/20... Step: 2580... Loss: 1.2422... Val Loss: 1.2864\n",
      "Epoch: 19/20... Step: 2590... Loss: 1.2178... Val Loss: 1.2822\n",
      "Epoch: 19/20... Step: 2600... Loss: 1.2252... Val Loss: 1.2847\n",
      "Epoch: 19/20... Step: 2610... Loss: 1.2252... Val Loss: 1.2829\n",
      "Epoch: 19/20... Step: 2620... Loss: 1.2024... Val Loss: 1.2826\n",
      "Epoch: 19/20... Step: 2630... Loss: 1.2178... Val Loss: 1.2772\n",
      "Epoch: 19/20... Step: 2640... Loss: 1.2179... Val Loss: 1.2849\n",
      "Epoch: 20/20... Step: 2650... Loss: 1.2256... Val Loss: 1.2807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20... Step: 2660... Loss: 1.2317... Val Loss: 1.2784\n",
      "Epoch: 20/20... Step: 2670... Loss: 1.2361... Val Loss: 1.2757\n",
      "Epoch: 20/20... Step: 2680... Loss: 1.2185... Val Loss: 1.2754\n",
      "Epoch: 20/20... Step: 2690... Loss: 1.2164... Val Loss: 1.2768\n",
      "Epoch: 20/20... Step: 2700... Loss: 1.2255... Val Loss: 1.2754\n",
      "Epoch: 20/20... Step: 2710... Loss: 1.1938... Val Loss: 1.2740\n",
      "Epoch: 20/20... Step: 2720... Loss: 1.1941... Val Loss: 1.2752\n",
      "Epoch: 20/20... Step: 2730... Loss: 1.1872... Val Loss: 1.2781\n",
      "Epoch: 20/20... Step: 2740... Loss: 1.1846... Val Loss: 1.2759\n",
      "Epoch: 20/20... Step: 2750... Loss: 1.1912... Val Loss: 1.2768\n",
      "Epoch: 20/20... Step: 2760... Loss: 1.1919... Val Loss: 1.2796\n",
      "Epoch: 20/20... Step: 2770... Loss: 1.2337... Val Loss: 1.2739\n",
      "Epoch: 20/20... Step: 2780... Loss: 1.2620... Val Loss: 1.2765\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "seq_length = 100\n",
    "n_epochs = 20 # start smaller if you are just testing initial behavior\n",
    "\n",
    "# train the model\n",
    "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfZxvNoDceEm"
   },
   "source": [
    "## Checkpoint\n",
    "\n",
    "После обучения сохраним модель, чтобы можно было загрузить ее позже. Здесь сохраняются параметры, необходимые для создания той же архитектуры, гиперпараметры скрытого слоя и токены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "q6RXl5VAceEm"
   },
   "outputs": [],
   "source": [
    "# change the name, for saving multiple files\n",
    "model_name = 'rnn_x_epoch.net'\n",
    "\n",
    "checkpoint = {'n_hidden': net.n_hidden,\n",
    "              'n_layers': net.n_layers,\n",
    "              'state_dict': net.state_dict(),\n",
    "              'tokens': net.chars}\n",
    "\n",
    "with open(model_name, 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2sJhx5iceEm"
   },
   "source": [
    "---\n",
    "## Делаем предсказания\n",
    "\n",
    "Теперь, когда мы обучили модель, сделаем предсказание следующих символов! Для предсказания мы передаем последний символ, и сеть предсказывает следующий символ, который мы потом передаем снова на вхол и получаем еще один предсказанный символ и так далее...\n",
    "\n",
    "Наши прогнозы основаны на категориальном распределении вероятностей по всем возможным символам. Мы можем ограничить число символов, чтобы сделать получаемый предсказанный текст более разумным, рассматривая только некоторые наиболее вероятные символы $K$. Это не позволит сети выдавать нам совершенно абсурдные прогнозы, а также позволит внести некоторый шум и случайность в выбранный текст. Узнать больше [можно здесь](https://pytorch.org/docs/stable/generated/torch.topk.html#torch.topk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEIRW_B2ceEm"
   },
   "outputs": [],
   "source": [
    "def predict(net, char, h=None, top_k=None):\n",
    "        ''' Given a character, predict the next character.\n",
    "            Returns the predicted character and the hidden state.\n",
    "        '''\n",
    "\n",
    "        # tensor inputs\n",
    "        x = np.array([[net.char2int[char]]])\n",
    "        x = one_hot_encode(x, len(net.chars))\n",
    "        inputs = torch.from_numpy(x)\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs = inputs.cuda()\n",
    "\n",
    "        # detach hidden state from history\n",
    "        h = tuple([each.data for each in h])\n",
    "        # get the output of the model\n",
    "        out, h = net(inputs, h)\n",
    "\n",
    "        # get the character probabilities\n",
    "        p = F.softmax(out, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "\n",
    "        # get top characters\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(net.chars))\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "\n",
    "        # select the likely next character with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "\n",
    "        # return the encoded value of the predicted char and the hidden state\n",
    "        return net.int2char[char], h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OG38j3gQceEm"
   },
   "source": [
    "### Priming и генерирование текста\n",
    "\n",
    "Нужно задать скрытое состояние, чтобы сеть не генерировала произвольные символы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9vpB5gRceEm"
   },
   "outputs": [],
   "source": [
    "def sample(net, size, prime='The', top_k=None):\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "    else:\n",
    "        net.cpu()\n",
    "\n",
    "    net.eval() # eval mode\n",
    "\n",
    "    # First off, run through the prime characters\n",
    "    chars = [ch for ch in prime]\n",
    "    h = net.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, h = predict(net, ch, h, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "\n",
    "    # Now pass in the previous character and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BqmFA9eEceEm"
   },
   "outputs": [],
   "source": [
    "print(sample(net, 1000, prime='Anna', top_k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "942mjdQHceEm"
   },
   "source": [
    "## Loading a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xt9ldUuSceEm"
   },
   "outputs": [],
   "source": [
    "# Here we have loaded in a model that trained over 20 epochs `rnn_20_epoch.net`\n",
    "with open('rnn_x_epoch.net', 'rb') as f:\n",
    "    checkpoint = torch.load(f)\n",
    "\n",
    "loaded = CharRNN(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
    "loaded.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ut6R3zDcceEm"
   },
   "outputs": [],
   "source": [
    "# Sample using a loaded model\n",
    "print(sample(loaded, 2000, top_k=5, prime=\"And Levin said\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rhp9qC8neCk"
   },
   "source": [
    "### Полезные ссылки:\n",
    "\n",
    "\n",
    "*   [Блог-пост Christopher'а Olah'а по LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4hWA4ABPs_F"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
