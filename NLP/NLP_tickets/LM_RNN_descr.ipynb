{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1W8R8WgZceEk"
   },
   "source": [
    "# NLP Tickets\n",
    "\n",
    "Fine-Tuning –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏.\n",
    "</br>–í–∑—è—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, BERT, GPT –∏–ª–∏ T5) –∏ –¥–æ–æ–±—É—á–∏—Ç—å –µ—ë –Ω–∞ –Ω–µ–±–æ–ª—å—à–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏:\n",
    "</br>–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∞: –∏–Ω—Ü–∏–¥–µ–Ω—Ç, –∑–∞–ø—Ä–æ—Å –∏ —Ç.–¥.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sqUOE2flceEl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª–∏–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω GPU, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ, –∏–Ω–∞—á–µ ‚Äî CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am reaching out regarding a high-priority ti...</td>\n",
       "      <td>Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am experiencing a high-priority incident whe...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am writing to express our concern regarding ...</td>\n",
       "      <td>Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I hope this message finds you well. I am writi...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I hope this message finds you well. My name is...</td>\n",
       "      <td>Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>I hope this message finds you well. I am writi...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>I am contacting you to report a critical servi...</td>\n",
       "      <td>Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>I am writing to bring to your attention a bill...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>I am facing a flickering issue on my Dell XPS ...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>Hello Customer Support, I am writing to expres...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body      type\n",
       "0     I am reaching out regarding a high-priority ti...   Request\n",
       "1     I am experiencing a high-priority incident whe...  Incident\n",
       "2     I am writing to express our concern regarding ...    Change\n",
       "3     I hope this message finds you well. I am writi...  Incident\n",
       "4     I hope this message finds you well. My name is...   Request\n",
       "...                                                 ...       ...\n",
       "3995  I hope this message finds you well. I am writi...  Incident\n",
       "3996  I am contacting you to report a critical servi...   Request\n",
       "3997  I am writing to bring to your attention a bill...  Incident\n",
       "3998  I am facing a flickering issue on my Dell XPS ...  Incident\n",
       "3999  Hello Customer Support, I am writing to expres...  Incident\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel —Ñ–∞–π–ª–∞\n",
    "data_df = pd.read_excel(\"dataset-tickets_en.xlsx\")\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    data_df[\"body\"], data_df[\"type\"], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3994       My MacBook Air M1 is shutting down frequently.\n",
       "423     \\n\\nI am experiencing issues with the ticket c...\n",
       "2991     I am writing to express my concern regarding ...\n",
       "1221    I am writing to inquire about certain charges ...\n",
       "506     \\n\\nI hope this message finds you well. I'm re...\n",
       "                              ...                        \n",
       "1130    Having trouble accessing channels and dispatch...\n",
       "1294    \\n\\nI am experiencing an issue with my Epson E...\n",
       "860     \\n\\nI am writing to request the implementation...\n",
       "3507    Dear Online Store Support Customer,<br><br>I h...\n",
       "3174    Our customer, <name>, is seeking assistance in...\n",
       "Name: body, Length: 3200, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "data_df = data_df.dropna(subset=[\"body\", \"type\"]).copy()\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∏–ø (–µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —ç—Ç–∏—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö –º–æ–≥—É—Ç –±—ã—Ç—å —á–∏—Å–ª–∞–º–∏)\n",
    "data_df[\"body\"] = data_df[\"body\"].astype(str)\n",
    "data_df[\"type\"] = data_df[\"type\"].astype(str)\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    data_df[\"body\"], data_df[\"type\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç Hugging Face Dataset\n",
    "train_data = Dataset.from_dict({\"text\": train_texts.tolist(), \"label\": train_labels.tolist()})\n",
    "test_data = Dataset.from_dict({\"text\": test_texts.tolist(), \"label\": test_labels.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c45e96cce414914ad5e1de98524526d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9189444dd74615b133ce8954c33d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç\n",
    "label2id = {label: idx for idx, label in enumerate(data_df[\"type\"].unique())}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "train_data = train_data.map(lambda x: {\"label\": label2id[x[\"label\"]]})\n",
    "test_data = test_data.map(lambda x: {\"label\": label2id[x[\"label\"]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilBERT\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ DistilBERT, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π Hugging Face.\n",
    "</br>DistilBERT –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤, –∫–∞–∫ –∏ –µ–≥–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å ‚Äî BERT (Bidirectional Encoder Representations from Transformers).\n",
    "</br>DistilBERT: –≠—Ç–æ –æ–±–ª–µ–≥—á—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏ BERT, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —É–º–µ–Ω—å—à–µ–Ω–∏—è –æ–±—ä—ë–º–∞ –ø–∞–º—è—Ç–∏ –±–µ–∑ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–µ—Ä—å –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏.\n",
    "</br>Uncased: –ú–æ–¥–µ–ª—å –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä —Ç–µ–∫—Å—Ç–∞ (–≤—Å—ë –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä).\n",
    "\n",
    "</br>DistilBERT —É–∂–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω –Ω–∞ –±–æ–ª—å—à–æ–º –∫–æ—Ä–ø—É—Å–µ —Ç–µ–∫—Å—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑ –í–∏–∫–∏–ø–µ–¥–∏–∏).\n",
    "</br>–í–µ—Ä—Ö–Ω—è—è —á–∞—Å—Ç—å –º–æ–¥–µ–ª–∏ (–≥–æ–ª–æ–≤–∞) –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –ª–∏–Ω–µ–π–Ω—ã–º —Å–ª–æ–µ–º, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã—Ö–æ–¥–æ–≤ –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ –¥–µ–ª–∞–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä?\n",
    "* –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ —á–∏—Å–ª–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –º–æ–≥–ª–∞ –µ–≥–æ –ø–æ–Ω—è—Ç—å.\n",
    "* –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Ç–æ–∫–µ–Ω—ã (—Å–ª–æ–≤–∞ –∏–ª–∏ —á–∞—Å—Ç–∏ —Å–ª–æ–≤) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–ª–≥–æ—Ä–∏—Ç–º–∞ BERT (WordPiece).\n",
    "* –î–æ–±–∞–≤–ª—è–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã, —Ç–∞–∫–∏–µ –∫–∞–∫ [CLS] (–¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏) –∏ [SEP] (—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å).\n",
    "* –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label2id) # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å\n",
    ")\n",
    "\n",
    "# –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ (tokenizer = AutoTokenizer.from_pretrained(model_name)) –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–±—ä–µ–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π –∑–Ω–∞–µ—Ç, –∫–∞–∫ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç. –û–¥–Ω–∞–∫–æ —Å–∞–º–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ–∑–∂–µ, –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö.\n",
    "</br>–ú–æ–¥–µ–ª—å DistilBERT –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ —Ç–µ–Ω–∑–æ—Ä—ã (Input IDs, Attention Masks –∏ —Ç.–¥.), –∞ –Ω–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏. –≠—Ç–æ—Ç –ø—Ä–æ—Ü–µ—Å—Å –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –Ω–∞ —ç—Ç–∞–ø–µ train_data.map(preprocess_data, batched=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae665670f6b4148a10e98c7d6a8b983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8056cb341ef4d0591c3cbd39e10e342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "def preprocess_data(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True, max_length=512)\n",
    "\n",
    "train_data = train_data.map(preprocess_data, batched=True)\n",
    "test_data = test_data.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 3199\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 800\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
    "train_data = train_data.remove_columns([\"text\"])\n",
    "test_data = test_data.remove_columns([\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 3199\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataCollatorWithPadding ‚Äî —ç—Ç–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Hugging Face, –∫–æ—Ç–æ—Ä—ã–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç padding (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω—É–ª–∏) –∫ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º –≤ –±–∞—Ç—á–µ —Ç–∞–∫, —á—Ç–æ–±—ã –≤—Å–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –±–∞—Ç—á–µ –∏–º–µ–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É.\n",
    "</br>–ï—Å–ª–∏ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç –≤ –±–∞—Ç—á–µ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ 50 —Ç–æ–∫–µ–Ω–æ–≤, –∞ –¥—Ä—É–≥–æ–π ‚Äî –∏–∑ 100, padding –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω—É–ª–∏ –∫ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–æ–º—É —Ç–µ–∫—Å—Ç—É, —á—Ç–æ–±—ã –µ–≥–æ –¥–ª–∏–Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª–∞ —Å–∞–º–æ–º—É –¥–ª–∏–Ω–Ω–æ–º—É –≤ –±–∞—Ç—á–µ.\n",
    "</br>DataCollatorWithPadding –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥–±–∏—Ä–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –±–∞—Ç—á–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ data collator –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø–∞–¥–¥–∏–Ω–≥–∞\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       "), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AADementev\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\", # –£–∫–∞–∑—ã–≤–∞–µ—Ç –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –≥–¥–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è.\n",
    "    evaluation_strategy=\"epoch\", # –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫ —á–∞—Å—Ç–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å –æ—Ü–µ–Ω–∫—É –º–æ–¥–µ–ª–∏ (–Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ). \"epoch\": –û—Ü–µ–Ω–∫–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏.\n",
    "    save_strategy=\"epoch\", # –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫ —á–∞—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –º–æ–¥–µ–ª—å (—á–µ–∫–ø–æ–∏–Ω—Ç—ã). \"epoch\": –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏.\n",
    "    learning_rate=2e-5, # –£–∫–∞–∑—ã–≤–∞–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (learning rate). –ó–Ω–∞—á–µ–Ω–∏–µ 2e-5: –≠—Ç–æ –Ω–µ–±–æ–ª—å—à–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (0.00002), —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –¥–ª—è —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–µ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤.\n",
    "    per_device_train_batch_size=4, # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–Ω–∞ –∫–∞–∂–¥–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä, GPU). –ó–Ω–∞—á–µ–Ω–∏–µ 4: –≠—Ç–æ –Ω–µ–±–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞, –ø–æ–¥—Ö–æ–¥—è—â–∏–π –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞–º—è—Ç–∏ GPU. \n",
    "    per_device_eval_batch_size=4, # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ). –ó–Ω–∞—á–µ–Ω–∏–µ 4: –¢–∞–∫–æ–µ –∂–µ, –∫–∞–∫ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ—Å—É—Ä—Å—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ.\n",
    "    num_train_epochs=10, #  –£–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö (–ø–æ–ª–Ω—ã—Ö –ø—Ä–æ—Ö–æ–¥–æ–≤ –ø–æ –≤—Å–µ–º—É —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É). \n",
    "    weight_decay=0.01, # –î–æ–±–∞–≤–ª—è–µ—Ç L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –∫ –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏, —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ. –ó–Ω–∞—á–µ–Ω–∏–µ 0.01: –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤, —á—Ç–æ–±—ã —Å–ª–µ–≥–∫–∞ —à—Ç—Ä–∞—Ñ–æ–≤–∞—Ç—å —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ –≤–µ—Å–∞.\n",
    "    logging_dir=\"./logs\", # –£–∫–∞–∑—ã–≤–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –≥–¥–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è –ª–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è.\n",
    "    logging_steps=10, # –£–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ —á–∞—Å—Ç–æ (–≤ —à–∞–≥–∞—Ö) –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏. –ó–Ω–∞—á–µ–Ω–∏–µ 10: –ö–∞–∂–¥—ã–µ 10 —à–∞–≥–æ–≤ –≤—ã–≤–æ–¥—è—Ç—Å—è –ª–æ–≥–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ—Ç–µ—Ä–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏).\n",
    "    load_best_model_at_end=True, # –£–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –≤ –∫–æ–Ω—Ü–µ –æ–±—É—á–µ–Ω–∏—è –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å (–Ω–∞ –æ—Å–Ω–æ–≤–µ —É–∫–∞–∑–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏). –ü–æ—á–µ–º—É –ø–æ–ª–µ–∑–Ω–æ: –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞–∏–ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–π —ç–ø–æ—Ö–µ, –∞ –≤ –æ–¥–Ω–æ–π –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö, –æ–Ω–∞ –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–∞.\n",
    "    metric_for_best_model=\"accuracy\", # –£–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∞—è –º–µ—Ç—Ä–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤—ã–±–æ—Ä–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏. \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º –æ–±—ä–µ–∫—Ç Trainer –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Hugging Face transformers, –∫–æ—Ç–æ—Ä—ã–π –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è, –æ—Ü–µ–Ω–∫–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AADementev\\AppData\\Local\\Temp\\ipykernel_5952\\1383386930.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ Trainer\n",
    "trainer = Trainer(\n",
    "    model=model, # –ú–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ü–µ—Ä–µ–¥–∞—ë—Ç—Å—è –º–æ–¥–µ–ª—å distilbert-base-uncased.\n",
    "    args=training_args, # –ü–µ—Ä–∞–¥–∞—ë—Ç—Å—è –æ–±—ä–µ–∫—Ç TrainingArguments, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è.\n",
    "    train_dataset=train_data, # –î–∞—Ç–∞—Å–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.\n",
    "    eval_dataset=test_data, # –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ (–≤–∞–ª–∏–¥–∞—Ü–∏–∏) –º–æ–¥–µ–ª–∏.\n",
    "    tokenizer=tokenizer, # –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–π –º–æ–¥–µ–ª–∏.\n",
    "    data_collator=data_collator, # –ü–µ—Ä–µ–¥–∞—ë—Ç—Å—è –æ–±—ä–µ–∫—Ç DataCollatorWithPadding. –£–ø—Ä–æ—â–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω–æ–π, –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è—è –ø–∞–¥–¥–∏–Ω–≥ –≤ –±–∞—Ç—á–∞—Ö.\n",
    "    compute_metrics=compute_metrics, # –ü–µ—Ä–µ–¥–∞—ë—Ç—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8000' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8000/8000 22:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.378500</td>\n",
       "      <td>1.258278</td>\n",
       "      <td>0.561250</td>\n",
       "      <td>0.429592</td>\n",
       "      <td>0.561250</td>\n",
       "      <td>0.466784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.156200</td>\n",
       "      <td>1.096333</td>\n",
       "      <td>0.598750</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.598750</td>\n",
       "      <td>0.560160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.818900</td>\n",
       "      <td>1.072285</td>\n",
       "      <td>0.653750</td>\n",
       "      <td>0.637928</td>\n",
       "      <td>0.653750</td>\n",
       "      <td>0.628986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.238300</td>\n",
       "      <td>1.108031</td>\n",
       "      <td>0.673750</td>\n",
       "      <td>0.664599</td>\n",
       "      <td>0.673750</td>\n",
       "      <td>0.667980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.565200</td>\n",
       "      <td>1.318631</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.684902</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.686031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.462700</td>\n",
       "      <td>1.362137</td>\n",
       "      <td>0.701250</td>\n",
       "      <td>0.711926</td>\n",
       "      <td>0.701250</td>\n",
       "      <td>0.704628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>1.455000</td>\n",
       "      <td>0.721250</td>\n",
       "      <td>0.709295</td>\n",
       "      <td>0.721250</td>\n",
       "      <td>0.713740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>1.558170</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>0.719023</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>0.723463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.612851</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.715469</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.717332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>1.640115</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.724694</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.727272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8000, training_loss=0.5371529834524262, metrics={'train_runtime': 1323.7914, 'train_samples_per_second': 24.165, 'train_steps_per_second': 6.043, 'total_flos': 3782451716146164.0, 'train_loss': 0.5371529834524262, 'epoch': 10.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-Tuning –º–æ–¥–µ–ª–∏\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5581698417663574, 'eval_accuracy': 0.7325, 'eval_precision': 0.7190228353958595, 'eval_recall': 0.7325, 'eval_f1': 0.7234626713409501, 'eval_runtime': 9.0889, 'eval_samples_per_second': 88.02, 'eval_steps_per_second': 22.005, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "    return id2label[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Request\n"
     ]
    }
   ],
   "source": [
    "new_text = \"I have a problem. My laptop is running slowly. Can you help me?\"\n",
    "print(f\"Classification: {predict(new_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Incident\n"
     ]
    }
   ],
   "source": [
    "new_text = \"A system update is required, the settings have been lost.\"\n",
    "print(f\"Classification: {predict(new_text)}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
