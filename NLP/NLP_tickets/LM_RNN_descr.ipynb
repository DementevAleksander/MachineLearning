{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1W8R8WgZceEk"
   },
   "source": [
    "# NLP Tickets\n",
    "\n",
    "Fine-Tuning модели для конкретной задачи.\n",
    "</br>Взять предобученную модель (например, BERT, GPT или T5) и дообучить её на небольшом наборе данных для специализированной задачи:\n",
    "</br>Классификация пользовательских запросов (например, техподдержка: инцидент, запрос и т.д.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sqUOE2flceEl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим устройство: если доступен GPU, используем его, иначе — CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am reaching out regarding a high-priority ti...</td>\n",
       "      <td>Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am experiencing a high-priority incident whe...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am writing to express our concern regarding ...</td>\n",
       "      <td>Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I hope this message finds you well. I am writi...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I hope this message finds you well. My name is...</td>\n",
       "      <td>Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>I hope this message finds you well. I am writi...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>I am contacting you to report a critical servi...</td>\n",
       "      <td>Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>I am writing to bring to your attention a bill...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>I am facing a flickering issue on my Dell XPS ...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>Hello Customer Support, I am writing to expres...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body      type\n",
       "0     I am reaching out regarding a high-priority ti...   Request\n",
       "1     I am experiencing a high-priority incident whe...  Incident\n",
       "2     I am writing to express our concern regarding ...    Change\n",
       "3     I hope this message finds you well. I am writi...  Incident\n",
       "4     I hope this message finds you well. My name is...   Request\n",
       "...                                                 ...       ...\n",
       "3995  I hope this message finds you well. I am writi...  Incident\n",
       "3996  I am contacting you to report a critical servi...   Request\n",
       "3997  I am writing to bring to your attention a bill...  Incident\n",
       "3998  I am facing a flickering issue on my Dell XPS ...  Incident\n",
       "3999  Hello Customer Support, I am writing to expres...  Incident\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка данных из Excel файла\n",
    "data_df = pd.read_excel(\"dataset-tickets_en.xlsx\")\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на тренировочную и тестовую выборки\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    data_df[\"body\"], data_df[\"type\"], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3994       My MacBook Air M1 is shutting down frequently.\n",
       "423     \\n\\nI am experiencing issues with the ticket c...\n",
       "2991     I am writing to express my concern regarding ...\n",
       "1221    I am writing to inquire about certain charges ...\n",
       "506     \\n\\nI hope this message finds you well. I'm re...\n",
       "                              ...                        \n",
       "1130    Having trouble accessing channels and dispatch...\n",
       "1294    \\n\\nI am experiencing an issue with my Epson E...\n",
       "860     \\n\\nI am writing to request the implementation...\n",
       "3507    Dear Online Store Support Customer,<br><br>I h...\n",
       "3174    Our customer, <name>, is seeking assistance in...\n",
       "Name: body, Length: 3200, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление строк с пустыми значениями в данных\n",
    "data_df = data_df.dropna(subset=[\"body\", \"type\"]).copy()\n",
    "\n",
    "# Преобразование колонок в строковый тип (если значения в этих колонках могут быть числами)\n",
    "data_df[\"body\"] = data_df[\"body\"].astype(str)\n",
    "data_df[\"type\"] = data_df[\"type\"].astype(str)\n",
    "\n",
    "# Разделение данных на тренировочную и тестовую выборки\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    data_df[\"body\"], data_df[\"type\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Преобразование данных в формат Hugging Face Dataset\n",
    "train_data = Dataset.from_dict({\"text\": train_texts.tolist(), \"label\": train_labels.tolist()})\n",
    "test_data = Dataset.from_dict({\"text\": test_texts.tolist(), \"label\": test_labels.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c45e96cce414914ad5e1de98524526d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9189444dd74615b133ce8954c33d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Преобразование меток в числовой формат\n",
    "label2id = {label: idx for idx, label in enumerate(data_df[\"type\"].unique())}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "train_data = train_data.map(lambda x: {\"label\": label2id[x[\"label\"]]})\n",
    "test_data = test_data.map(lambda x: {\"label\": label2id[x[\"label\"]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilBERT\n",
    "\n",
    "Используем предобученную версию модели-трансформера DistilBERT, предоставленная библиотекой Hugging Face.\n",
    "</br>DistilBERT основан на архитектуре трансформеров, как и его оригинальная модель — BERT (Bidirectional Encoder Representations from Transformers).\n",
    "</br>DistilBERT: Это облегчённая версия модели BERT, оптимизированная для скорости и уменьшения объёма памяти без значительных потерь в точности.\n",
    "</br>Uncased: Модель не учитывает регистр текста (всё преобразуется в нижний регистр).\n",
    "\n",
    "</br>DistilBERT уже предобучен на большом корпусе текстов (например, из Википедии).\n",
    "</br>Верхняя часть модели (голова) заменяется линейным слоем, который предназначен для классификации на основе выходов модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что делает токенизатор?\n",
    "* Преобразует текст в числовое представление, чтобы модель могла его понять.\n",
    "* Разбивает текст на токены (слова или части слов) с использованием алгоритма BERT (WordPiece).\n",
    "* Добавляет специальные токены, такие как [CLS] (для классификации) и [SEP] (разделитель).\n",
    "* Проверяет, что длина текста соответствует ограничениям модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка токенизатора и модели\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label2id) # количество классов, которые модель должна предсказывать\n",
    ")\n",
    "\n",
    "# Переносим модель на нужное устройство\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка токенизатора (tokenizer = AutoTokenizer.from_pretrained(model_name)) предоставляет объект, который знает, как токенизировать текст. Однако сама токенизация текста происходит позже, при подготовке данных.\n",
    "</br>Модель DistilBERT принимает на вход только числовые тензоры (Input IDs, Attention Masks и т.д.), а не текстовые строки. Этот процесс выполняется на этапе train_data.map(preprocess_data, batched=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae665670f6b4148a10e98c7d6a8b983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8056cb341ef4d0591c3cbd39e10e342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Токенизация данных\n",
    "def preprocess_data(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True, max_length=512)\n",
    "\n",
    "train_data = train_data.map(preprocess_data, batched=True)\n",
    "test_data = test_data.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 3199\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 800\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление ненужных колонок\n",
    "train_data = train_data.remove_columns([\"text\"])\n",
    "test_data = test_data.remove_columns([\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 3199\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataCollatorWithPadding — это инструмент из библиотеки Hugging Face, который автоматически добавляет padding (дополнительные нули) к токенизированным последовательностям в батче так, чтобы все последовательности в батче имели одинаковую длину.\n",
    "</br>Если один текст в батче состоит из 50 токенов, а другой — из 100, padding добавляет нули к более короткому тексту, чтобы его длина соответствовала самому длинному в батче.\n",
    "</br>DataCollatorWithPadding автоматически подбирает максимальную длину токенов для каждого конкретного батча."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание data collator для динамического паддинга\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       "), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение метрик для оценки\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AADementev\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Настройка параметров обучения\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\", # Указывает путь к директории, где будут сохраняться результаты обучения.\n",
    "    evaluation_strategy=\"epoch\", # Определяет, как часто выполнять оценку модели (на тестовой выборке). \"epoch\": Оценка выполняется в конце каждой эпохи.\n",
    "    save_strategy=\"epoch\", # Определяет, как часто сохранять модель (чекпоинты). \"epoch\": Сохранение модели в конце каждой эпохи.\n",
    "    learning_rate=2e-5, # Указывает скорость обучения (learning rate). Значение 2e-5: Это небольшая скорость обучения (0.00002), часто используемая для тонкой настройки моделей трансформеров.\n",
    "    per_device_train_batch_size=4, # Устанавливает размер батча для тренировочных данных (на каждом устройстве, например, GPU). Значение 4: Это небольшой размер батча, подходящий для трансформеров, чтобы избежать переполнения памяти GPU. \n",
    "    per_device_eval_batch_size=4, # Устанавливает размер батча для тестовых данных (при оценке). Значение 4: Такое же, как для тренировочных данных, чтобы использовать ресурсы эффективно.\n",
    "    num_train_epochs=10, #  Указывает количество эпох (полных проходов по всему тренировочному датасету). \n",
    "    weight_decay=0.01, # Добавляет L2-регуляризацию к весам модели, чтобы предотвратить переобучение. Значение 0.01: Рекомендуемое значение для трансформеров, чтобы слегка штрафовать слишком большие веса.\n",
    "    logging_dir=\"./logs\", # Указывает директорию, где будут сохраняться логи обучения.\n",
    "    logging_steps=10, # Указывает, как часто (в шагах) логировать метрики. Значение 10: Каждые 10 шагов выводятся логи (например, потери и метрики).\n",
    "    load_best_model_at_end=True, # Указывает, что в конце обучения нужно загрузить лучшую модель (на основе указанной метрики). Почему полезно: Если модель показывает наилучшие результаты не в последней эпохе, а в одной из предыдущих, она будет загружена.\n",
    "    metric_for_best_model=\"accuracy\", # Указывает, какая метрика используется для выбора лучшей модели. \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим объект Trainer из библиотеки Hugging Face transformers, который автоматизирует процесс обучения, оценки и логирования модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AADementev\\AppData\\Local\\Temp\\ipykernel_5952\\1383386930.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта Trainer\n",
    "trainer = Trainer(\n",
    "    model=model, # Модель для обучения. Передаётся модель distilbert-base-uncased.\n",
    "    args=training_args, # Перадаётся объект TrainingArguments, содержащий параметры обучения.\n",
    "    train_dataset=train_data, # Датасет, используемый для обучения модели.\n",
    "    eval_dataset=test_data, # Датасет для оценки (валидации) модели.\n",
    "    tokenizer=tokenizer, # Токенизатор, соответствующий используемой модели.\n",
    "    data_collator=data_collator, # Передаётся объект DataCollatorWithPadding. Упрощает обработку данных с разной длиной, динамически добавляя паддинг в батчах.\n",
    "    compute_metrics=compute_metrics, # Передаётся пользовательская функция для вычисления метрик.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8000' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8000/8000 22:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.378500</td>\n",
       "      <td>1.258278</td>\n",
       "      <td>0.561250</td>\n",
       "      <td>0.429592</td>\n",
       "      <td>0.561250</td>\n",
       "      <td>0.466784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.156200</td>\n",
       "      <td>1.096333</td>\n",
       "      <td>0.598750</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.598750</td>\n",
       "      <td>0.560160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.818900</td>\n",
       "      <td>1.072285</td>\n",
       "      <td>0.653750</td>\n",
       "      <td>0.637928</td>\n",
       "      <td>0.653750</td>\n",
       "      <td>0.628986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.238300</td>\n",
       "      <td>1.108031</td>\n",
       "      <td>0.673750</td>\n",
       "      <td>0.664599</td>\n",
       "      <td>0.673750</td>\n",
       "      <td>0.667980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.565200</td>\n",
       "      <td>1.318631</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.684902</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.686031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.462700</td>\n",
       "      <td>1.362137</td>\n",
       "      <td>0.701250</td>\n",
       "      <td>0.711926</td>\n",
       "      <td>0.701250</td>\n",
       "      <td>0.704628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>1.455000</td>\n",
       "      <td>0.721250</td>\n",
       "      <td>0.709295</td>\n",
       "      <td>0.721250</td>\n",
       "      <td>0.713740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>1.558170</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>0.719023</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>0.723463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.612851</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.715469</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.717332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>1.640115</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.724694</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.727272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8000, training_loss=0.5371529834524262, metrics={'train_runtime': 1323.7914, 'train_samples_per_second': 24.165, 'train_steps_per_second': 6.043, 'total_flos': 3782451716146164.0, 'train_loss': 0.5371529834524262, 'epoch': 10.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-Tuning модели\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5581698417663574, 'eval_accuracy': 0.7325, 'eval_precision': 0.7190228353958595, 'eval_recall': 0.7325, 'eval_f1': 0.7234626713409501, 'eval_runtime': 9.0889, 'eval_samples_per_second': 88.02, 'eval_steps_per_second': 22.005, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Оценка модели\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример использования модели на новых данных\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # Переносим входные данные на нужное устройство\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "    return id2label[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Request\n"
     ]
    }
   ],
   "source": [
    "new_text = \"I have a problem. My laptop is running slowly. Can you help me?\"\n",
    "print(f\"Classification: {predict(new_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Incident\n"
     ]
    }
   ],
   "source": [
    "new_text = \"A system update is required, the settings have been lost.\"\n",
    "print(f\"Classification: {predict(new_text)}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
