{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b039b3",
   "metadata": {},
   "source": [
    "# Откуда берутся датасеты? Практический проект по сбору данных и работе с текстами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b765aae",
   "metadata": {},
   "source": [
    "<b>Цель.</b> В этом домашнем задании вам предстоит обойти все ловушки серверов, пробраться сквозь страницы html-код, собрать себе свой собственный датасет и натренировать на нём модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae3d2b9-0575-456e-b209-d5ebc1d2e8ce",
   "metadata": {},
   "source": [
    "<b>Описание/Пошаговая инструкция выполнения домашнего задания:</b>\n",
    "\n",
    "<b>Часть 1. Парсинг.</b>\n",
    "</br>По аналогии с занятием, возьмите интересующий вас сайт, на котором можно пособирать какие-то данные (и при этом API не предоставляется).\n",
    "</br>Напишите свой парсер, который будет бегать по страничкам и автоматически что-то собирать.\n",
    "Не забывайте, что парсинг - это ответственное мероприятие, поэтому не бомбардируйте несчастные сайты слишком частыми запросами (можно ограничить число запросов в секунду при помощи time.sleep(0.3), вставленного в теле цикла).\n",
    "\n",
    "<b>Часть 2. NLP.</b>\n",
    "1. Разбейте собранные данные на train/test, отложив 20-30% наблюдений для тестирования.\n",
    "2. Примените tf-idf преобразование для текстового описания. Используйте как отдельные токены, так и биграммы, отсейте стоп-слова, а также слова, которые встречаются слишком редко или слишком часто (параметры min/max_df), не забудьте убрать l2 регуляризацию, которая по умолчанию включена.\n",
    "3. Если в вашем датасете целевая переменная непрерывная (например, среднее число просмотров в день), то воспользуйтесь линейной регрессией, если дискретная (положительный/отрицательный отзыв), то логистической.\n",
    "4. Постройте регрессию с настройкой параметра регуляризации, оцените качество при помощи соответствующих задаче метрик.\n",
    "5. Визуализируйте получившиеся коэффициенты регрессии (возьмите топ-50 слов).\n",
    "6. Проинтерпретируйте результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d705fafe",
   "metadata": {},
   "source": [
    "# Выполнение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfaaab8-a589-48f2-a544-f4f9c00f85e3",
   "metadata": {},
   "source": [
    "Будем собирать отзывы и оценку по 5ти бальной шкале с сайта https://irecommend.ru/ по теме \"Банки и банковские продукты\".\n",
    "</br>Первая страница банковских продуктов: https://irecommend.ru/catalog/rating/22\n",
    "</br>Начиная со второй страницы ссылка выглядит так: https://irecommend.ru/catalog/rating/22?page=1\n",
    "</br>Переберём все страницы с банковскими продуктами до тех пор пока не получим список всех ссылок на отзыв (пока не получим пустой массив или не наткнёмся на ответ 302 Found). </br>Ссылки будем получать из тега с классом class=\"read-all-reviews-link-bottom read-all-reviews-link\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b949075-fc0c-47f0-aeb6-344e52bd1534",
   "metadata": {},
   "source": [
    "Импортируем основные библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a907fbd-4630-403f-b0d7-5d275ae74252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import urllib3\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "# Отключить предупреждения о непроверенных HTTPS-запросах\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "def load_proxies(file_path):\n",
    "    proxies = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()[1:]  # Пропустить заголовок\n",
    "        for line in lines:\n",
    "            ip, port = line.strip().split(',')\n",
    "            proxies.append(f\"{ip}:{port}\")\n",
    "    return proxies\n",
    "\n",
    "def load_user_agents(file_path):\n",
    "    user_agents = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()[1:]  # Пропустить заголовок\n",
    "        for line in lines:\n",
    "            user_agents.append(line.strip())\n",
    "    return user_agents\n",
    "\n",
    "proxies = load_proxies('proxies.csv')\n",
    "user_agents = load_user_agents('user_agents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2992fc0a-9603-4ee3-9cd7-8f636a81fc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество прокси: 300\n",
      "Вывод первых 10 прокси:\n",
      "50.168.163.178:80\n",
      "50.221.74.130:80\n",
      "50.168.72.115:80\n",
      "50.174.7.162:80\n",
      "50.172.75.121:80\n",
      "50.222.245.44:80\n",
      "50.217.226.43:80\n",
      "50.171.122.30:80\n",
      "68.185.57.66:80\n",
      "50.168.72.122:80\n"
     ]
    }
   ],
   "source": [
    "# Вывод длины массива\n",
    "print(\"Количество прокси:\", len(proxies))\n",
    "\n",
    "# Вывод первых 10 записей массива\n",
    "print(\"Вывод первых 10 прокси:\")\n",
    "for link in proxies[:10]:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d533537-c22b-40c2-9f5b-90e628bec01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество user_agents: 300\n",
      "Вывод первых 10 user_agents:\n",
      "\"Mozilla/5.0 (Linux; Android 8.0.0; SM-G935F Build/R16NW; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/116.0.0.0 Mobile Safari/537.36\"\n",
      "\"Mozilla/5.0 (Linux; Android 12; SM-A035M Build/SP1A.210812.016; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/108.0.5359.128 Mobile Safari/537.36\"\n",
      "\"TuneIn Radio Pro/26.2.1; iPhone13,2; iOS/16.6.1\"\n",
      "\"Mozilla/5.0 (Linux; Android 12; SM-A315G Build/SP1A.210812.016; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/116.0.0.0 Mobile Safari/537.36 Instagram 300.0.0.29.110 Android (31/12; 420dpi; 1080x2195; samsung; SM-A315G; a31; mt6768; it_IT; 515103471)\"\n",
      "\"Mozilla/5.0 (Linux; Android 12; LM-Q920N Build/SKQ1.211103.001; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/96.0.4664.104 Mobile Safari/537.36\"\n",
      "\"Mozilla/5.0 (Linux; Android 10; MI 8 Build/QKQ1.190828.002; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/117.0.0.0 Mobile Safari/537.36\"\n",
      "\"Mozilla/5.0 (Linux; Android 13; CPH2273 Build/TP1A.220905.001; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/116.0.0.0 Mobile Safari/537.36\"\n",
      "\"Mozilla/5.0 (Linux; Android 10; SM-J600FN Build/QP1A.190711.020; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/116.0.0.0 Mobile Safari/537.36\"\n",
      "\"Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/21A329 Instagram 300.0.0.15.103 (iPhone12,3; iOS 17_0; it_IT; it; scale=3.00; 1125x2436; 514327624)\"\n",
      "\"Mozilla/5.0 (Linux; arm_64; Android 11; CPH2127) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.5745.22 Mobile Safari/537.36\"\n"
     ]
    }
   ],
   "source": [
    "# Вывод длины массива\n",
    "print(\"Количество user_agents:\", len(user_agents))\n",
    "\n",
    "# Вывод первых 10 записей массива\n",
    "print(\"Вывод первых 10 user_agents:\")\n",
    "for link in user_agents[:10]:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57efe81-b12d-4b2c-8eed-ec057cdad8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отключиv предупреждения о непроверенных HTTPS-запросах\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "def get_review_links(session, page_url, headers):\n",
    "    try:\n",
    "        response = session.get(page_url, headers=headers, verify=False)\n",
    "        if response.status_code == 302:  # Перенаправление указывает на конец страницы\n",
    "            return []\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        review_links = []\n",
    "        for link in soup.find_all('a', class_='read-all-reviews-link-bottom read-all-reviews-link'):\n",
    "            review_links.append(urljoin(page_url, link.get('href')))\n",
    "        return review_links\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_review_links(base_url, start_page=0):\n",
    "    ua = UserAgent()\n",
    "    all_links = []\n",
    "    page = start_page\n",
    "    with requests.Session() as session:\n",
    "        while True:\n",
    "            headers = {'User-Agent': ua.random}\n",
    "            if page == 0:\n",
    "                page_url = base_url\n",
    "            else:\n",
    "                page_url = f\"{base_url}?page={page}\"\n",
    "            links = get_review_links(session, page_url, headers)\n",
    "            if not links:  # Если ссылки не найдены, прерываем цикл\n",
    "                break\n",
    "            all_links.extend(links)\n",
    "            page += 1\n",
    "            time.sleep(0.3)  # Задержка между запросами\n",
    "    return all_links\n",
    "\n",
    "def save_links_to_file(links, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(links, f)\n",
    "\n",
    "def load_links_from_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7c6c761-bf25-43f7-86e5-9b472426d7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество ссылок: 340\n",
      "Вывод первых 10 ссылок:\n",
      "https://irecommend.ru/content/vsegda-da\n",
      "https://irecommend.ru/content/detskaya-karta-tinkoff-junior\n",
      "https://irecommend.ru/content/alfa-bank-premium\n",
      "https://irecommend.ru/content/tinkoff-drive-debetovaya-karta-drive\n",
      "https://irecommend.ru/content/nakopitelnyi-alfa-schet-1\n",
      "https://irecommend.ru/content/debetovaya-karta-tinkoff-lamoda\n",
      "https://irecommend.ru/content/ipoteka-tinkoff-0\n",
      "https://irecommend.ru/content/programma-urozhai-ot-rosselkhozbanka\n",
      "https://irecommend.ru/content/kredit-nalichnymi-ot-tinkoff-bank-1\n",
      "https://irecommend.ru/content/kreditnaya-karta-tinkoff-all-airlines-0\n"
     ]
    }
   ],
   "source": [
    "# Базовый URL-адрес для первоначального списка отзывов\n",
    "base_url = \"https://irecommend.ru/catalog/rating/22\"\n",
    "\n",
    "# Загрузим все ссылки на просмотр с начальных страниц\n",
    "all_review_links = load_links_from_file('all_review_links.json')\n",
    "if not all_review_links:\n",
    "    all_review_links = scrape_all_review_links(base_url)\n",
    "    save_links_to_file(all_review_links, 'all_review_links.json')\n",
    "\n",
    "# Вывод длины массива\n",
    "print(\"Количество ссылок:\", len(all_review_links))\n",
    "\n",
    "# Вывод первых 10 записей массива\n",
    "print(\"Вывод первых 10 ссылок:\")\n",
    "for link in all_review_links[:10]:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8163c3d0-bb19-4b95-8d0b-c3d09320e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_snippet_links(session, product_url, headers):\n",
    "    try:\n",
    "        response = session.get(product_url, headers=headers, verify=False)\n",
    "        if response.status_code != 200:\n",
    "            return []\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        snippet_links = []\n",
    "        for link in soup.find_all('a', class_='reviewTextSnippet'):\n",
    "            snippet_links.append(urljoin(product_url, link.get('href')))\n",
    "        return snippet_links\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_snippet_links(all_review_links):\n",
    "    usag = UserAgent()\n",
    "    all_snippet_links = []\n",
    "    with requests.Session() as session:\n",
    "        for product_link in all_review_links:\n",
    "            headers = {'User-Agent': usag.random}\n",
    "            snippet_links = get_review_snippet_links(session, product_link, headers)\n",
    "            all_snippet_links.extend(snippet_links)\n",
    "            time.sleep(0.3)\n",
    "    return all_snippet_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb44834b-6cfb-46d0-9b2b-d51f7f473252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество ссылок: 1061\n",
      "Вывод первых 10 ссылок:\n",
      "https://irecommend.ru/content/poidi-tuda-neznamo-kuda-i-prinesi-neznamo-chto-ili-istoriya-o-tom-kak-ne-zashchishcheny-nash\n",
      "https://irecommend.ru/content/zachem-rebenku-bankovskaya-karta-s-tinkoff-junior-deti-uchatsya-ne-tolko-tratit-dengi-no-i-z\n",
      "https://irecommend.ru/content/kartu-rekomenduyu-poskolku-v-ee-nalichii-bolshe-plyusov-chem-minusov-i-blagodarya-besplatnom\n",
      "https://irecommend.ru/content/detskaya-karta-tinkoff-junior-sovremennyi-i-udobnyi-sposob-vydachi-karmannykh-deneg-rebenku\n",
      "https://irecommend.ru/content/dva-v-odnom-karta-i-mini-shkola-finansovoi-gramotnosti\n",
      "https://irecommend.ru/content/karta-blagodarya-kotoroi-rebenok-s-detstva-uchitsya-upravlyat-finansami-vse-po-vzroslomu-poc\n",
      "https://irecommend.ru/content/klassnaya-karta-no-est-nyuans\n",
      "https://irecommend.ru/content/syn-teper-ne-nosit-meloch-i-poluchaet-dop-dengi-za-vypolnennye-zadaniya-i-glavnoe-ya-vsegda\n",
      "https://irecommend.ru/content/banku-bezrazlichno-ponyatie-detskaya-psikhologiya-i-etika\n",
      "https://irecommend.ru/content/debetovaya-karta-tinkoff-dzhunior-karta-mir-s-kotoroi-ne-tolko-udobno-no-i-mozhno-obuchat-re\n"
     ]
    }
   ],
   "source": [
    "all_snippet_links = load_links_from_file('all_snippet_links.json')\n",
    "if not all_snippet_links:\n",
    "    all_snippet_links = scrape_all_snippet_links(all_review_links)\n",
    "    save_links_to_file(all_snippet_links, 'all_snippet_links.json')\n",
    "\n",
    "print(\"Количество ссылок:\", len(all_snippet_links))\n",
    "\n",
    "print(\"Вывод первых 10 ссылок:\")\n",
    "for link in all_snippet_links[:10]:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1179f88-ad1c-4a92-9273-82738e952d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85ca784-d226-4c24-b890-4cc0a1510c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5de66-b991-455b-916b-2dd65496bf5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a038d-4831-4695-9d55-1efd8ef93446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb874d3-4e8f-49cc-9232-de92324665ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db70c3ed-85fd-4f88-895e-183099dd8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_snippet_links(session, product_url, headers):\n",
    "    try:\n",
    "        response = session.get(product_url, headers=headers, verify=False)\n",
    "        if response.status_code != 200:\n",
    "            return []\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        snippet_links = []\n",
    "        for link in soup.find_all('a', class_='reviewTextSnippet'):\n",
    "            snippet_links.append(urljoin(product_url, link.get('href')))\n",
    "        return snippet_links\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_snippet_links(all_review_links):\n",
    "    usag = UserAgent()\n",
    "    all_snippet_links = []\n",
    "    with requests.Session() as session:\n",
    "        for product_link in all_review_links:\n",
    "            headers = {'User-Agent': usag.random}\n",
    "            snippet_links = get_review_snippet_links(session, product_link, headers)\n",
    "            all_snippet_links.extend(snippet_links)\n",
    "            time.sleep(0.3)\n",
    "    return all_snippet_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e6554-9c31-4f1b-889f-18c8258e1f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_snippet_links = load_links_from_file('all_snippet_links.json')\n",
    "if not all_snippet_links:\n",
    "    all_snippet_links = scrape_all_snippet_links(all_review_links)\n",
    "    save_links_to_file(all_snippet_links, 'all_snippet_links.json')\n",
    "\n",
    "print(\"Количество ссылок:\", len(all_snippet_links))\n",
    "\n",
    "print(\"Вывод первых 10 ссылок:\")\n",
    "for link in all_snippet_links[:10]:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f71ae-8c1f-424a-9db8-42a4ce3c2733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d5d174-f54c-43fb-96b8-a4ed660e254c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d7eae-e47f-4941-8b14-56957e9cd6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b5476a-1b51-449a-a2a9-150a98a32304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8811def-f6a4-4674-9375-c71f409f72c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351ccf83-c289-4677-afc7-bc5429ced8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea1bc02-e1f1-4814-a8cf-3c3930b931bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c235b2-4be8-4d03-8a7d-5b0a6432a648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e49ed4-1f3d-40b8-9074-a02ec0590da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3557193d-13b9-49cd-8166-0712d9d61002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c699915f-9f31-4488-8d0c-b5d1bc6512d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_proxy():\n",
    "    return random.choice(proxies)\n",
    "\n",
    "def get_random_user_agent():\n",
    "    return random.choice(user_agents)\n",
    "\n",
    "def get_review_links(session, page_url, headers, proxy):\n",
    "    try:\n",
    "        response = session.get(page_url, headers=headers, proxies={\"http\": proxy, \"https\": proxy}, verify=False)\n",
    "        if response.status_code == 302:  # Перенаправление указывает на конец страницы\n",
    "            return []\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        review_links = []\n",
    "        for link in soup.find_all('a', class_='read-all-reviews-link-bottom read-all-reviews-link'):\n",
    "            review_links.append(urljoin(page_url, link.get('href')))\n",
    "        return review_links\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def save_links_to_file(links, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(links, f)\n",
    "\n",
    "def get_review_snippet_links(session, product_url, headers, proxy):\n",
    "    try:\n",
    "        response = session.get(product_url, headers=headers, proxies={\"http\": proxy, \"https\": proxy}, verify=False)\n",
    "        if response.status_code != 200:\n",
    "            return []\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        snippet_links = []\n",
    "        for link in soup.find_all('a', class_='reviewTextSnippet'):\n",
    "            snippet_links.append(urljoin(product_url, link.get('href')))\n",
    "        return snippet_links\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def scrape_snippet_links_for_product(session, product_link):\n",
    "    headers = {'User-Agent': get_random_user_agent()}\n",
    "    proxy = get_random_proxy()\n",
    "    return get_review_snippet_links(session, product_link, headers, proxy)\n",
    "\n",
    "def scrape_all_snippet_links(all_review_links):\n",
    "    all_snippet_links = []\n",
    "    with requests.Session() as session:\n",
    "        for product_link in all_review_links:\n",
    "            snippet_links = scrape_snippet_links_for_product(session, product_link)\n",
    "            all_snippet_links.extend(snippet_links)\n",
    "            time.sleep(random.uniform(0.5, 2.0))  # Случайная задержка\n",
    "    return all_snippet_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d07d7-08e7-49d4-8f8e-2de6db3fbd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_links_from_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d9e49-3e10-45de-8b51-067ea9aa3a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_review_links(base_url, start_page=0):\n",
    "    all_links = []\n",
    "    page = start_page\n",
    "    with requests.Session() as session:\n",
    "        while True:\n",
    "            headers = {'User-Agent': get_random_user_agent()}\n",
    "            proxy = get_random_proxy()\n",
    "            if page == 0:\n",
    "                page_url = base_url\n",
    "            else:\n",
    "                page_url = f\"{base_url}?page={page}\"\n",
    "            links = get_review_links(session, page_url, headers, proxy)\n",
    "            if not links:  # Если ссылки не найдены, прерываем цикл\n",
    "                break\n",
    "            all_links.extend(links)\n",
    "            page += 1\n",
    "            time.sleep(random.uniform(0.3, 0.5))  # Случайная задержка между запросами\n",
    "    return all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee2b514-16ab-4671-abb6-6b68e67fab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовый URL-адрес для первоначального списка отзывов\n",
    "base_url = \"https://irecommend.ru/catalog/rating/22\"\n",
    "\n",
    "# Загрузим все ссылки на просмотр с начальных страниц\n",
    "all_review_links = load_links_from_file('all_review_links.json')\n",
    "if not all_review_links:\n",
    "    all_review_links = scrape_all_review_links(base_url)\n",
    "    save_links_to_file(all_review_links, 'all_review_links.json')\n",
    "\n",
    "# Вывод длины массива\n",
    "print(\"Количество ссылок:\", len(all_review_links))\n",
    "\n",
    "# Вывод первых 10 записей массива\n",
    "print(\"Вывод первых 10 ссылок:\")\n",
    "for link in all_review_links[:10]:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac36cc-4196-4e8d-96ee-c273d681ba6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e24b0-3a22-43ae-985f-b0cb3090e86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03678ff6-f96a-46b1-b337-723e18f7dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_review_data_for_link(session, review_link, max_retries):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        headers = {\n",
    "            'User-Agent': get_random_user_agent(),\n",
    "            'Accept-Language': 'en-US,en;q=0.9',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Referer': review_link\n",
    "        }\n",
    "        proxy = get_random_proxy()\n",
    "        try:\n",
    "            response = session.get(review_link, headers=headers, proxies={\"http\": proxy, \"https\": proxy}, verify=False)\n",
    "            if response.status_code == 521:\n",
    "                print(f\"Server error on {review_link}, status code: 521. Retrying...\")\n",
    "                retries += 1\n",
    "                time.sleep(random.uniform(0.5, 2.0))\n",
    "                continue\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Failed to load page: {review_link}, status code: {response.status_code}\")\n",
    "                break\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            # Получаем текст отзыва\n",
    "            review_div = soup.find('div', class_='description hasinlineimage')\n",
    "            if not review_div:\n",
    "                print(f\"No review text found on: {review_link}\")\n",
    "                break\n",
    "            review_text = \" \".join(p.get_text(separator=' ', strip=True) for p in review_div.find_all('p'))\n",
    "\n",
    "            # Получаем рейтинг\n",
    "            rating_meta = soup.find('meta', itemprop='ratingValue')\n",
    "            if not rating_meta:\n",
    "                print(f\"No rating found on: {review_link}\")\n",
    "                break\n",
    "            rating_value = rating_meta.get('content')\n",
    "\n",
    "            print(f\"Scraped review: {review_text[:30]}..., Rating: {rating_value}\")\n",
    "            return {'text_review': review_text, 'rating_review': rating_value}\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            retries += 1\n",
    "            time.sleep(random.uniform(0.5, 2.0))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab36d47-d62b-4538-ad8c-103623fa9ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовый URL-адрес для первоначального списка отзывов\n",
    "base_url = \"https://irecommend.ru/catalog/rating/22\"\n",
    "\n",
    "# Загрузим все ссылки на просмотр с начальных страниц\n",
    "all_review_links = load_links_from_file('all_review_links.json')\n",
    "if not all_review_links:\n",
    "    all_review_links = scrape_all_review_links(base_url)\n",
    "    save_links_to_file(all_review_links, 'all_review_links.json')\n",
    "\n",
    "# Вывод длины массива\n",
    "print(\"Количество ссылок:\", len(all_review_links))\n",
    "\n",
    "# Вывод первых 10 записей массива\n",
    "print(\"Вывод первых 10 ссылок:\")\n",
    "for link in all_review_links[:10]:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f37ca-e429-417f-97f9-84eb9b164d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим все ссылки на сниппеты отзывов\n",
    "all_snippet_links = load_links_from_file('all_snippet_links.json')\n",
    "if not all_snippet_links:\n",
    "    all_snippet_links = scrape_all_snippet_links(all_review_links)\n",
    "    save_links_to_file(all_snippet_links, 'all_snippet_links.json')\n",
    "\n",
    "print(\"Количество ссылок:\", len(all_snippet_links))\n",
    "\n",
    "print(\"Вывод первых 10 ссылок:\")\n",
    "for link in all_snippet_links[:10]:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cae7ab-f821-4487-891c-600306d9ed8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95977a8e-7bd2-4d61-980d-d5b3286d6091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf49b68-198a-45f7-812c-3e4807e6af28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781313c8-2e03-47e2-b7c4-f2cdee18d426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a55db5-f24f-40b8-b74f-a644cf446dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_review_data(all_snippet_links, max_retries=2):\n",
    "    reviews_data = []\n",
    "    with requests.Session() as session:\n",
    "        for review_link in all_snippet_links:\n",
    "            review_data = scrape_review_data_for_link(session, review_link, max_retries)\n",
    "            if review_data:\n",
    "                reviews_data.append(review_data)\n",
    "            time.sleep(random.uniform(0.5, 2.0))\n",
    "    return reviews_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97509836-ea43-4622-a1c2-af3e8b7d2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сбор данных отзывов\n",
    "filename = 'reviews_dataset.csv'\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    if df.empty:\n",
    "        print(\"Файл 'reviews_dataset.csv' пуст.\")\n",
    "    else:\n",
    "        print(\"Данные успешно загружены из файла 'reviews_dataset.csv'.\")\n",
    "else:\n",
    "    print(\"В файле 'reviews_dataset.csv' не найдено никаких данных, пытаюсь восстановить данные отзывов...\")\n",
    "    reviews_data = scrape_review_data(all_snippet_links)\n",
    "    df = pd.DataFrame(reviews_data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(\"Данные успешно обработаны и сохранены в файле 'reviews_dataset.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30cbf12-6c5c-4370-9d1c-d991a545f358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48065a3c-4389-413a-9a72-9df7e502fafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062a3ac-e7f7-4048-a59c-d5b76ccac780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e884b-c0f3-475e-a5b0-2f87a0f32ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ca090b-4d14-4c98-a249-73198542141d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291efe5c-ffec-44d7-8410-7495a88ff86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a896a-5fef-4edb-8e23-33cf32763df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b97bea-ca01-492e-8388-0cb8e53e8b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48021b6f-4eb1-4f40-8b48-15a6d07250cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdcc201-4036-4162-8f44-ea32dc725981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e20b1-f2ec-473e-8553-b5bcc87addda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7016ace1-b86f-4dab-a151-600275ea728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4438270a-ff76-4814-8e0b-df0def28dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd65f746-42d2-41c5-a73e-f5aabdb95655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2eda6c-c3b4-4a6f-a366-b7a84f78d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление строк с пустыми значениями в колонке text_review\n",
    "df = df.dropna(subset=['text_review'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be3cbde-c736-4ec9-b71d-4b8e42b89211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подсчет количества значений по классам в признаке \"rating_review\"\n",
    "rating_counts = df['rating_review'].value_counts().sort_index()\n",
    "\n",
    "# Построение графика\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(rating_counts.index, rating_counts.values, color='skyblue')\n",
    "plt.xlabel('Rating Review')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of Values by Classes in \"rating_review\"')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Показать график\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
